{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ğŸš€ Enhanced Khmer OCR Hyperparameter Tuning\n",
        "\n",
        "**âœ¨ NEW FEATURES:**\n",
        "- ğŸ’¾ **Google Drive Integration** - No more lost models!\n",
        "- ğŸ”„ **Resumable Training** - Continue from where you left off\n",
        "- ğŸ“Š **Persistent Results** - All data saved to Drive\n",
        "- ğŸ›¡ï¸ **Crash Recovery** - Automatically resume after disconnection\n",
        "\n",
        "## ğŸ“‹ Quick Start:\n",
        "1. âœ… Enable GPU: Runtime â†’ Change runtime type â†’ GPU\n",
        "2. âœ… Run all cells in order\n",
        "3. âœ… Results automatically saved to Drive!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# ğŸ”§ Initial Setup\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "print(f\"ğŸ Python: {sys.version}\")\n",
        "print(f\"ğŸ”¥ PyTorch: {torch.__version__}\")\n",
        "print(f\"âš¡ CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q opencv-python-headless albumentations tensorboard efficientnet-pytorch Pillow pyyaml tqdm\n",
        "print(\"âœ… Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drive-setup"
      },
      "outputs": [],
      "source": [
        "# ğŸ’¾ Google Drive Integration\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "print(\"ğŸ” Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Setup Drive paths\n",
        "DRIVE_ROOT = '/content/drive/MyDrive'\n",
        "PROJECT_DRIVE_PATH = f'{DRIVE_ROOT}/Khmer_OCR_Experiments'\n",
        "MODELS_DRIVE_PATH = f'{PROJECT_DRIVE_PATH}/training_output'\n",
        "RESULTS_DRIVE_PATH = f'{PROJECT_DRIVE_PATH}/results'\n",
        "\n",
        "# Create directories\n",
        "for path in [PROJECT_DRIVE_PATH, MODELS_DRIVE_PATH, RESULTS_DRIVE_PATH]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "print(f\"âœ… Drive mounted: {PROJECT_DRIVE_PATH}\")\n",
        "print(f\"ğŸ—ï¸ Models: {MODELS_DRIVE_PATH}\")\n",
        "print(f\"ğŸ“Š Results: {RESULTS_DRIVE_PATH}\")\n",
        "\n",
        "# Create symlinks\n",
        "for link in ['drive_training_output', 'drive_results']:\n",
        "    if os.path.exists(link):\n",
        "        os.unlink(link)\n",
        "        \n",
        "os.symlink(MODELS_DRIVE_PATH, 'drive_training_output')\n",
        "os.symlink(RESULTS_DRIVE_PATH, 'drive_results')\n",
        "print(\"ğŸ”— Symlinks created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload-files"
      },
      "source": [
        "## ğŸ“ Upload Project Files\n",
        "\n",
        "**Option 1: Upload ZIP file** (Recommended)\n",
        "- Compress your entire project folder\n",
        "- Upload and extract using the cell below\n",
        "\n",
        "**Option 2: Clone from GitHub** (if your project is on GitHub)\n",
        "- Use the git clone cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload-project"
      },
      "outputs": [],
      "source": [
        "# Option 1: Upload ZIP file\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "print(\"ğŸ“ Upload your project ZIP file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract the uploaded ZIP\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"ğŸ“¦ Extracting {filename}...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(f\"âœ… Extracted {filename}\")\n",
        "\n",
        "# List contents to verify\n",
        "print(\"\\nğŸ“‚ Current directory contents:\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone-github"
      },
      "outputs": [],
      "source": [
        "# Option 2: Clone from GitHub (uncomment and modify URL)\n",
        "# !git clone https://github.com/yourusername/khmer-ocr-digits.git\n",
        "# %cd khmer-ocr-digits\n",
        "# print(\"âœ… Project cloned from GitHub\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-paths"
      },
      "outputs": [],
      "source": [
        "# Setup project paths\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Find project root (adjust path if needed)\n",
        "project_root = None\n",
        "for root in ['.', './khmer-ocr-digits', '../']:\n",
        "    if os.path.exists(os.path.join(root, 'src')):\n",
        "        project_root = Path(root).resolve()\n",
        "        break\n",
        "\n",
        "if project_root:\n",
        "    os.chdir(project_root)\n",
        "    sys.path.append(str(project_root / 'src'))\n",
        "    print(f\"âœ… Project root: {project_root}\")\n",
        "else:\n",
        "    print(\"âŒ Could not find project root. Please check your upload.\")\n",
        "    !ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "verify-setup"
      },
      "source": [
        "## âœ… Verify Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test-imports"
      },
      "outputs": [],
      "source": [
        "# Test imports to verify everything is working\n",
        "try:\n",
        "    from modules.data_utils import KhmerDigitsDataset\n",
        "    from models import create_model\n",
        "    from modules.trainers import OCRTrainer\n",
        "    from modules.trainers.utils import setup_training_environment, TrainingConfig\n",
        "    print(\"âœ… All imports successful!\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Import error: {e}\")\n",
        "    print(\"Please check your project structure and file uploads.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-data"
      },
      "outputs": [],
      "source": [
        "# Check if data files exist\n",
        "required_files = [\n",
        "    'generated_data/metadata.yaml',\n",
        "    'config/phase3_training_configs.yaml',\n",
        "    'config/model_config.yaml'\n",
        "]\n",
        "\n",
        "print(\"ğŸ“‹ Checking required files:\")\n",
        "all_files_exist = True\n",
        "for file_path in required_files:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"âœ… {file_path}\")\n",
        "    else:\n",
        "        print(f\"âŒ {file_path} - NOT FOUND\")\n",
        "        all_files_exist = False\n",
        "\n",
        "if all_files_exist:\n",
        "    print(\"\\nğŸ‰ All required files found! Ready to start training.\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ Some files are missing. Please check your upload.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "resumable-check"
      },
      "source": [
        "## ğŸ” Check for Resumable Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-resumable"
      },
      "outputs": [],
      "source": [
        "# Check for existing experiments that can be resumed\n",
        "import glob\n",
        "import json\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def find_resumable_experiments():\n",
        "    \"\"\"Find experiments that can be resumed.\"\"\"\n",
        "    resumable = []\n",
        "    exp_dirs = glob.glob(f'{MODELS_DRIVE_PATH}/*')\n",
        "    \n",
        "    for exp_dir in exp_dirs:\n",
        "        if os.path.isdir(exp_dir):\n",
        "            exp_name = os.path.basename(exp_dir)\n",
        "            checkpoint_dir = os.path.join(exp_dir, 'checkpoints')\n",
        "            \n",
        "            if os.path.exists(checkpoint_dir):\n",
        "                checkpoints = glob.glob(f'{checkpoint_dir}/checkpoint_epoch_*.pth')\n",
        "                if checkpoints:\n",
        "                    latest_checkpoint = sorted(checkpoints)[-1]\n",
        "                    epoch_num = int(latest_checkpoint.split('_epoch_')[1].split('.pth')[0])\n",
        "                    \n",
        "                    # Check config for total epochs\n",
        "                    total_epochs = 50  # Default\n",
        "                    config_file = os.path.join(exp_dir, 'config.yaml')\n",
        "                    if os.path.exists(config_file):\n",
        "                        try:\n",
        "                            import yaml\n",
        "                            with open(config_file, 'r') as f:\n",
        "                                config = yaml.safe_load(f)\n",
        "                                total_epochs = config.get('num_epochs', 50)\n",
        "                        except:\n",
        "                            pass\n",
        "                    \n",
        "                    is_complete = epoch_num >= total_epochs\n",
        "                    \n",
        "                    resumable.append({\n",
        "                        'experiment_name': exp_name,\n",
        "                        'latest_epoch': epoch_num,\n",
        "                        'total_epochs': total_epochs,\n",
        "                        'is_complete': is_complete,\n",
        "                        'checkpoint_path': latest_checkpoint,\n",
        "                        'experiment_dir': exp_dir,\n",
        "                        'progress': f\"{epoch_num}/{total_epochs}\"\n",
        "                    })\n",
        "    \n",
        "    return resumable\n",
        "\n",
        "def display_resumable_table(experiments):\n",
        "    \"\"\"Display resumable experiments in HTML table.\"\"\"\n",
        "    if not experiments:\n",
        "        print(\"ğŸ“‚ No previous experiments found in Drive.\")\n",
        "        return\n",
        "        \n",
        "    html = \"\"\"\n",
        "    <div style=\"border: 2px solid #2196F3; padding: 15px; margin: 10px 0; border-radius: 10px; background: #f8f9fa;\">\n",
        "        <h3>ğŸ”„ Found Resumable Experiments</h3>\n",
        "        <table style=\"width: 100%; border-collapse: collapse; border: 1px solid #ddd;\">\n",
        "            <thead>\n",
        "                <tr style=\"background: #2196F3; color: white;\">\n",
        "                    <th style=\"border: 1px solid #ddd; padding: 8px;\">Experiment</th>\n",
        "                    <th style=\"border: 1px solid #ddd; padding: 8px;\">Progress</th>\n",
        "                    <th style=\"border: 1px solid #ddd; padding: 8px;\">Status</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "    \"\"\"\n",
        "    \n",
        "    for exp in experiments:\n",
        "        status = \"âœ… Complete\" if exp['is_complete'] else \"ğŸ”„ Resumable\"\n",
        "        bg_color = \"#e8f5e8\" if exp['is_complete'] else \"#fff3cd\"\n",
        "        \n",
        "        html += f\"\"\"\n",
        "            <tr style=\"background: {bg_color};\">\n",
        "                <td style=\"border: 1px solid #ddd; padding: 8px;\">{exp['experiment_name']}</td>\n",
        "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">{exp['progress']}</td>\n",
        "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">{status}</td>\n",
        "            </tr>\n",
        "        \"\"\"\n",
        "    \n",
        "    html += \"\"\"\n",
        "            </tbody>\n",
        "        </table>\n",
        "        <p style=\"margin-top: 10px; color: #666; font-style: italic;\">\n",
        "            ğŸ’¡ Incomplete experiments will automatically resume from their last checkpoint.\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    \n",
        "    display(HTML(html))\n",
        "\n",
        "# Find and display resumable experiments\n",
        "resumable_experiments = find_resumable_experiments()\n",
        "display_resumable_table(resumable_experiments)\n",
        "\n",
        "# Save for later use\n",
        "with open('resumable_experiments.json', 'w') as f:\n",
        "    json.dump(resumable_experiments, f, indent=2)\n",
        "\n",
        "print(f\"ğŸ’¾ Found {len(resumable_experiments)} existing experiments\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enhanced-tuner"
      },
      "source": [
        "## ğŸš€ Enhanced Hyperparameter Tuning\n",
        "\n",
        "**âš ï¸ IMPORTANT:** For the complete enhanced functionality, use the enhanced script instead:\n",
        "\n",
        "```python\n",
        "# Load the complete enhanced trainer\n",
        "exec(open('src/sample_scripts/enhanced_colab_trainer.py').read())\n",
        "\n",
        "# Use enhanced tuner\n",
        "tuner = EnhancedColabHyperparameterTuner(\n",
        "    drive_models_path=MODELS_DRIVE_PATH,\n",
        "    drive_results_path=RESULTS_DRIVE_PATH\n",
        ")\n",
        "tuner.run_experiments()\n",
        "```\n",
        "\n",
        "Below is a simplified version for demonstration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enhanced-script"
      },
      "outputs": [],
      "source": [
        "# Load the complete enhanced trainer script\n",
        "try:\n",
        "    print(\"ğŸ”§ Loading enhanced trainer script...\")\n",
        "    exec(open('src/sample_scripts/enhanced_colab_trainer.py').read())\n",
        "    print(\"âœ… Enhanced trainer loaded successfully!\")\n",
        "    \n",
        "    # Initialize the enhanced tuner\n",
        "    tuner = EnhancedColabHyperparameterTuner(\n",
        "        drive_models_path=MODELS_DRIVE_PATH,\n",
        "        drive_results_path=RESULTS_DRIVE_PATH,\n",
        "        auto_resume=True\n",
        "    )\n",
        "    \n",
        "    print(\"\\nğŸ¯ Enhanced tuner ready! Usage options:\")\n",
        "    print(\"\\n1. Run all experiments:\")\n",
        "    print(\"   tuner.run_experiments()\")\n",
        "    print(\"\\n2. Run specific experiments:\")\n",
        "    print(\"   tuner.run_experiments(['conservative_small', 'baseline_optimized'])\")\n",
        "    print(\"\\n3. Quick test (single experiment):\")\n",
        "    print(\"   tuner.run_experiments(['conservative_small'])\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ Enhanced trainer script not found.\")\n",
        "    print(\"Please ensure 'src/sample_scripts/enhanced_colab_trainer.py' exists in your project.\")\n",
        "    print(\"\\nğŸ’¡ You can still use the basic functionality below.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading enhanced trainer: {e}\")\n",
        "    print(\"\\nğŸ’¡ You can still use the basic functionality below.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quick-start"
      },
      "source": [
        "## ğŸƒâ€â™‚ï¸ Quick Start Training\n",
        "\n",
        "**If enhanced script loaded successfully, run this:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quick-test"
      },
      "outputs": [],
      "source": [
        "# Quick test with one experiment (if enhanced tuner is available)\n",
        "if 'tuner' in globals():\n",
        "    print(\"ğŸ§ª Running quick test with conservative_small configuration...\")\n",
        "    print(\"This will automatically resume if the experiment was previously started.\")\n",
        "    \n",
        "    # Run just one experiment for testing\n",
        "    tuner.run_experiments(['conservative_small'])\n",
        "    \n",
        "    # Save results\n",
        "    results_file = tuner.save_results()\n",
        "    print(f\"\\nğŸ’¾ Results saved to: {results_file}\")\n",
        "    \n",
        "else:\n",
        "    print(\"âš ï¸ Enhanced tuner not available. Please load the enhanced script first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-all"
      },
      "outputs": [],
      "source": [
        "# Run all experiments (if enhanced tuner is available)\n",
        "if 'tuner' in globals():\n",
        "    print(\"ğŸš€ Starting full hyperparameter tuning...\")\n",
        "    print(\"â° This will take 45-60 minutes with GPU acceleration.\")\n",
        "    print(\"ğŸ’¡ Training will automatically resume if interrupted.\")\n",
        "    \n",
        "    # Run all experiments with auto-resume\n",
        "    tuner.run_experiments()\n",
        "    \n",
        "    # Save final results\n",
        "    results_file = tuner.save_results()\n",
        "    \n",
        "    print(f\"\\nğŸ‰ Hyperparameter tuning completed!\")\n",
        "    if tuner.best_result:\n",
        "        print(f\"ğŸ† Best result: {tuner.best_result['experiment_name']}\")\n",
        "        print(f\"ğŸ“Š Character accuracy: {tuner.best_result['best_val_char_accuracy']:.1%}\")\n",
        "        print(f\"ğŸ“Š Sequence accuracy: {tuner.best_result['best_val_seq_accuracy']:.1%}\")\n",
        "    \n",
        "    print(f\"\\nğŸ’¾ Results saved to: {results_file}\")\n",
        "    print(f\"ğŸ“ Models saved to: {MODELS_DRIVE_PATH}\")\n",
        "    \n",
        "else:\n",
        "    print(\"âš ï¸ Enhanced tuner not available. Please load the enhanced script first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "basic-fallback"
      },
      "source": [
        "## ğŸ”§ Basic Fallback (If Enhanced Script Not Available)\n",
        "\n",
        "This provides basic functionality without the enhanced features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "basic-trainer"
      },
      "outputs": [],
      "source": [
        "# Basic trainer fallback (without enhanced features)\n",
        "import yaml\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Only run if enhanced tuner is not available\n",
        "if 'tuner' not in globals():\n",
        "    print(\"ğŸ”§ Setting up basic trainer...\")\n",
        "    \n",
        "    # Load config\n",
        "    with open('config/phase3_training_configs.yaml', 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    \n",
        "    print(f\"ğŸ“‹ Found {len(config['experiments'])} experiments:\")\n",
        "    for exp_name in config['experiments'].keys():\n",
        "        print(f\"  - {exp_name}\")\n",
        "    \n",
        "    print(\"\\nğŸ’¡ To run experiments manually:\")\n",
        "    print(\"1. Load the enhanced script: exec(open('src/sample_scripts/enhanced_colab_trainer.py').read())\")\n",
        "    print(\"2. Or use the original notebook: colab_hyperparameter_tuning.ipynb\")\n",
        "    \n",
        "else:\n",
        "    print(\"âœ… Enhanced tuner is available - no need for basic fallback.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-results"
      },
      "source": [
        "## ğŸ“¥ Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Download results and model checkpoints\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "# Find result files\n",
        "result_files = glob.glob(f\"{RESULTS_DRIVE_PATH}/colab_hyperparameter_results_*.json\")\n",
        "checkpoint_dirs = glob.glob(f\"{MODELS_DRIVE_PATH}/*\")\n",
        "\n",
        "print(\"ğŸ“ Available for download:\")\n",
        "print(f\"\\nğŸ“Š Results files: {len(result_files)}\")\n",
        "for f in result_files:\n",
        "    print(f\"  - {os.path.basename(f)}\")\n",
        "\n",
        "print(f\"\\nğŸ—ï¸ Experiment directories: {len(checkpoint_dirs)}\")\n",
        "for d in checkpoint_dirs:\n",
        "    if os.path.isdir(d):\n",
        "        print(f\"  - {os.path.basename(d)}/\")\n",
        "\n",
        "# Download latest results\n",
        "if result_files:\n",
        "    latest_results = sorted(result_files)[-1]\n",
        "    print(f\"\\nğŸ“¥ Downloading latest results: {os.path.basename(latest_results)}\")\n",
        "    files.download(latest_results)\n",
        "\n",
        "# Create and download summary zip\n",
        "if checkpoint_dirs:\n",
        "    zip_filename = f\"khmer_ocr_training_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n",
        "    \n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        # Add result files\n",
        "        for f in result_files:\n",
        "            zipf.write(f, os.path.basename(f))\n",
        "        \n",
        "        # Add best models only to save space\n",
        "        for exp_dir in checkpoint_dirs:\n",
        "            if os.path.isdir(exp_dir):\n",
        "                exp_name = os.path.basename(exp_dir)\n",
        "                best_model = os.path.join(exp_dir, 'checkpoints', 'best_model.pth')\n",
        "                if os.path.exists(best_model):\n",
        "                    zipf.write(best_model, f\"{exp_name}_best_model.pth\")\n",
        "    \n",
        "    print(f\"\\nğŸ“¦ Downloading summary package: {zip_filename}\")\n",
        "    files.download(zip_filename)\n",
        "\n",
        "print(\"\\nâœ… Download completed!\")\n",
        "print(f\"ğŸ”— All files remain available in your Drive: {PROJECT_DRIVE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## ğŸ“‹ Summary & Next Steps\n",
        "\n",
        "### ğŸ‰ What You've Accomplished:\n",
        "- âœ… **Google Drive Integration**: All models and results safely stored\n",
        "- âœ… **Resumable Training**: Can continue after any disconnection\n",
        "- âœ… **GPU Acceleration**: ~10x faster training than CPU\n",
        "- âœ… **Persistent Results**: Everything saved permanently to Drive\n",
        "\n",
        "### ğŸ“Š Expected Results:\n",
        "- **Best Configuration**: conservative_small\n",
        "- **Expected Character Accuracy**: 45-60% (with full epochs)\n",
        "- **Target Goal**: 85% character accuracy\n",
        "\n",
        "### ğŸ”„ If Training Was Interrupted:\n",
        "Simply re-run the notebook - it will automatically detect and resume incomplete experiments!\n",
        "\n",
        "### ğŸš€ Next Steps:\n",
        "1. **Analyze Results**: Check which configuration performed best\n",
        "2. **Fine-tune**: Run refined experiments around the best parameters\n",
        "3. **Deploy**: Use the best model for production OCR tasks\n",
        "4. **Share**: Your Drive folder can be shared with collaborators\n",
        "\n",
        "### ğŸ“ Your Drive Structure:\n",
        "```\n",
        "ğŸ“ MyDrive/Khmer_OCR_Experiments/\n",
        "â”œâ”€â”€ ğŸ“ training_output/     (All model checkpoints)\n",
        "â””â”€â”€ ğŸ“ results/            (JSON results files)\n",
        "```\n",
        "\n",
        "ğŸ¯ **Happy Training with Enhanced Colab!** ğŸš€\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
