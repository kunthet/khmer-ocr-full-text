{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "T8hFD9zpHkMq",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Khmer OCR Hyperparameter Tuning on Google Colab\n",
    "\n",
    "This notebook performs systematic hyperparameter tuning for Khmer digits OCR model optimization.\n",
    "\n",
    "**Features:**\n",
    "- Complete setup from scratch on Google Colab\n",
    "- GPU acceleration support\n",
    "- Automatic data generation\n",
    "- Multiple hyperparameter experiments\n",
    "- Google Drive integration for model storage\n",
    "- Real-time training monitoring\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🚨 IMPORTANT: Which Cells to Run\n",
    "\n",
    "**✅ FOR SUCCESSFUL HYPERPARAMETER TUNING, RUN THESE CELLS:**\n",
    "\n",
    "1. **Cells 1-33**: Setup and data generation (run all)\n",
    "2. **Cell 36**: `StandaloneHyperparameterTuner` class definition  \n",
    "3. **Cell 38**: Quick test (optional but recommended)\n",
    "4. **Cell 39**: Run all experiments (main hyperparameter tuning)\n",
    "\n",
    "**❌ DO NOT RUN THESE DISABLED CELLS:**\n",
    "- Cell 48: Old results saving (disabled)\n",
    "- Cell 51: Old model loading (disabled)\n",
    "\n",
    "**📁 Results Location:**\n",
    "- Models: `/content/drive/MyDrive/khmer_ocr_training/models/`\n",
    "- Results: `/content/drive/MyDrive/khmer_ocr_training/results/`\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Khmer OCR Hyperparameter Tuning on Google Colab\n",
    "\n",
    "This notebook performs systematic hyperparameter tuning for Khmer digits OCR model optimization.\n",
    "\n",
    "**Features:**\n",
    "- Complete setup from scratch on Google Colab\n",
    "- GPU acceleration support\n",
    "- Automatic data generation\n",
    "- Multiple hyperparameter experiments\n",
    "- Google Drive integration for model storage\n",
    "- Real-time training monitoring\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "ySbB8x_GHkMq",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Environment Setup & Google Drive Mount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1944,
     "status": "ok",
     "timestamp": 1750704676126,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "LF3rXbNzHkMr",
    "outputId": "ee4bb54b-7139-4bc9-99e3-dfc5f18eb11a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "✅ Google Drive mounted successfully!\n",
      "📁 Project directory: /content/drive/MyDrive/khmer_ocr_training\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive for saving models and results\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directory for our project in Google Drive\n",
    "project_drive_path = '/content/drive/MyDrive/khmer_ocr_training'\n",
    "os.makedirs(project_drive_path, exist_ok=True)\n",
    "os.makedirs(f'{project_drive_path}/models', exist_ok=True)\n",
    "os.makedirs(f'{project_drive_path}/results', exist_ok=True)\n",
    "os.makedirs(f'{project_drive_path}/logs', exist_ok=True)\n",
    "\n",
    "print(f\"✅ Google Drive mounted successfully!\")\n",
    "print(f\"📁 Project directory: {project_drive_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4748,
     "status": "ok",
     "timestamp": 1750704680870,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "slCCtfJkHkMs",
    "outputId": "6228bb0a-c7d9-4148-8308-7dd91c15347c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU device: Tesla T4\n",
      "GPU memory: 14.7 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ GPU not available, will use CPU (training will be slower)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "X4RXOo_nHkMs",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Clone Repository & Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1750704680932,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "WeK5xFGnHkMt",
    "outputId": "c0d1cec1-f167-4638-91ef-9bc3d4f23546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Repository already exists at /content/khmer-ocr-digits\n",
      "📁 Current directory: /content/khmer-ocr-digits\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Change to content directory\n",
    "os.chdir('/content')\n",
    "\n",
    "# Clone repository - REPLACE THIS URL WITH YOUR ACTUAL REPOSITORY URL\n",
    "repo_url = \"https://github.com/kunthet/khmer-ocr-digits.git\"  # Replace with actual URL\n",
    "repo_name = 'khmer-ocr-digits'\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(\"📥 Cloning repository...\")\n",
    "    try:\n",
    "        result = subprocess.run(['git', 'clone', repo_url], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"✅ Repository cloned successfully!\")\n",
    "        else:\n",
    "            print(f\"❌ Clone failed: {result.stderr}\")\n",
    "            print(\"Creating directory structure manually for demo...\")\n",
    "            os.makedirs(repo_name, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error cloning repository: {e}\")\n",
    "        print(\"Creating directory structure manually for demo...\")\n",
    "        os.makedirs(repo_name, exist_ok=True)\n",
    "else:\n",
    "    print(f\"✅ Repository already exists at /content/{repo_name}\")\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(f'/content/{repo_name}')\n",
    "print(f\"📁 Current directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27166,
     "status": "ok",
     "timestamp": 1750704708100,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "Gbubbix0HkMt",
    "outputId": "b02fa34f-23a0-4790-96b4-6d38e9e41450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Installing compatible PyTorch with CUDA support...\n",
      "✅ Running in Google Colab - using pre-installed PyTorch\n",
      "Using pre-installed PyTorch 2.6.0+cu124\n",
      "📦 Installing core dependencies...\n",
      "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.14.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet_pytorch) (2.6.0+cu124)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
      "📦 Installing visualization and utilities...\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (8.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "📦 Installing font and text processing libraries...\n",
      "Requirement already satisfied: fonttools in /usr/local/lib/python3.11/dist-packages (4.58.4)\n",
      "Requirement already satisfied: freetype-py in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
      "Requirement already satisfied: unicodedata2 in /usr/local/lib/python3.11/dist-packages (16.0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
      "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.2.1)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
      "📦 Installing Jupyter widgets...\n",
      "✅ All dependencies installed successfully!\n",
      "🔥 PyTorch version: 2.6.0+cu124\n",
      "🔥 PyTorch CUDA available: True\n",
      "🔥 CUDA version: 12.4\n",
      "🔥 cuDNN version: 90100\n",
      "🔥 GPU device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "print(\"📦 Installing compatible PyTorch with CUDA support...\")\n",
    "\n",
    "# Use the pre-installed PyTorch in Colab or install compatible version\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"✅ Running in Google Colab - using pre-installed PyTorch\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"🔧 Not in Colab - installing PyTorch manually\")\n",
    "\n",
    "if not IN_COLAB:\n",
    "    # Only install PyTorch if not in Colab\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\", \"--extra-index-url\", \"https://download.pytorch.org/whl/cu118\"])\n",
    "else:\n",
    "    # In Colab, use the pre-installed PyTorch or reinstall compatible version\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"Using pre-installed PyTorch {torch.__version__}\")\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\"])\n",
    "\n",
    "print(\"📦 Installing core dependencies...\")\n",
    "%pip install efficientnet_pytorch opencv-python Pillow numpy scipy pandas h5py\n",
    "\n",
    "print(\"📦 Installing visualization and utilities...\")\n",
    "%pip install matplotlib seaborn tensorboard PyYAML omegaconf tqdm click\n",
    "\n",
    "# Skip wandb for now to avoid conflicts\n",
    "print(\"📦 Installing font and text processing libraries...\")\n",
    "%pip install fonttools freetype-py unicodedata2 scikit-learn scikit-image\n",
    "\n",
    "print(\"📦 Installing Jupyter widgets...\")\n",
    "%pip install ipywidgets --quiet\n",
    "\n",
    "print(\"✅ All dependencies installed successfully!\")\n",
    "\n",
    "# Verify PyTorch CUDA installation\n",
    "import torch\n",
    "print(f\"🔥 PyTorch version: {torch.__version__}\")\n",
    "print(f\"🔥 PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"🔥 CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"🔥 cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"🔥 GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"⚠️ CUDA not available - will use CPU (slower training)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1750704708470,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "lgrzkPrFHkMu",
    "outputId": "a29dd9b8-1edd-4ab5-828c-a2fa978604bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Checking and fixing cuDNN compatibility...\n",
      "✅ cuDNN working correctly!\n",
      "🎯 Device preference set to: cuda\n"
     ]
    }
   ],
   "source": [
    "# Fix cuDNN compatibility issues in Google Colab\n",
    "print(\"🔧 Checking and fixing cuDNN compatibility...\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    # Test CUDA functionality\n",
    "    if torch.cuda.is_available():\n",
    "        # Try to create a simple tensor to test cuDNN\n",
    "        test_tensor = torch.randn(1, 1, 10, 10).cuda()\n",
    "        test_conv = torch.nn.Conv2d(1, 1, 3).cuda()\n",
    "        _ = test_conv(test_tensor)\n",
    "        print(\"✅ cuDNN working correctly!\")\n",
    "    else:\n",
    "        print(\"⚠️ CUDA not available, using CPU\")\n",
    "\n",
    "except Exception as e:\n",
    "    if \"cudnnGetLibConfig\" in str(e):\n",
    "        print(\"🚨 cuDNN compatibility issue detected!\")\n",
    "        print(\"🔄 Applying fix...\")\n",
    "\n",
    "        # Restart runtime and reinstall PyTorch with compatible version\n",
    "        print(\"Please restart the runtime (Runtime -> Restart runtime) and run this cell again.\")\n",
    "        print(\"If the issue persists, use CPU training by setting device='cpu' in the configuration.\")\n",
    "\n",
    "        # Alternative: Force CPU usage\n",
    "        import os\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "        print(\"⚠️ Forcing CPU usage due to cuDNN issues\")\n",
    "    else:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "\n",
    "# Set device preference\n",
    "device_preference = 'cuda' if torch.cuda.is_available() and 'CUDA_VISIBLE_DEVICES' not in os.environ else 'cpu'\n",
    "print(f\"🎯 Device preference set to: {device_preference}\")\n",
    "\n",
    "# Update the configuration to use CPU if CUDA has issues\n",
    "import os\n",
    "if device_preference == 'cpu':\n",
    "    print(\"📝 Updating configuration for CPU training...\")\n",
    "    # We'll adjust batch sizes and other settings for CPU later\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "G66gFbbXHkMu",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 🚨 Alternative Fix for cuDNN Issues\n",
    "\n",
    "If you're still encountering the `cudnnGetLibConfig` error, try these alternative solutions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1750704708519,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "AzjrwN6FHkMu",
    "outputId": "74b91390-da40-441f-9ffd-7fd01de4bc1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Alternative cuDNN fixes:\n",
      "1. Restart runtime and try again\n",
      "2. Use specific PyTorch version\n",
      "3. Force CPU training\n",
      "💡 If none of these work, restart the runtime and run all cells again.\n",
      "💡 The notebook will automatically adapt to CPU training if GPU fails.\n"
     ]
    }
   ],
   "source": [
    "# Alternative cuDNN fix - Run this cell only if you're still having issues\n",
    "\n",
    "print(\"🔧 Alternative cuDNN fixes:\")\n",
    "print(\"1. Restart runtime and try again\")\n",
    "print(\"2. Use specific PyTorch version\")\n",
    "print(\"3. Force CPU training\")\n",
    "\n",
    "# Option 1: Install specific PyTorch version that's known to work with Colab\n",
    "def fix_cudnn_option1():\n",
    "    print(\"🔄 Installing PyTorch 2.0.1 with CUDA 11.8...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.run([\n",
    "        sys.executable, \"-m\", \"pip\", \"install\",\n",
    "        \"torch==2.0.1\", \"torchvision==0.15.2\", \"torchaudio==2.0.2\",\n",
    "        \"--index-url\", \"https://download.pytorch.org/whl/cu118\"\n",
    "    ])\n",
    "\n",
    "# Option 2: Force CPU training\n",
    "def fix_cudnn_option2():\n",
    "    print(\"🔄 Forcing CPU training...\")\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "    global device_preference\n",
    "    device_preference = 'cpu'\n",
    "\n",
    "# Option 3: Use CPU-only PyTorch\n",
    "def fix_cudnn_option3():\n",
    "    print(\"🔄 Installing CPU-only PyTorch...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.run([\n",
    "        sys.executable, \"-m\", \"pip\", \"install\",\n",
    "        \"torch\", \"torchvision\", \"torchaudio\",\n",
    "        \"--index-url\", \"https://download.pytorch.org/whl/cpu\"\n",
    "    ])\n",
    "\n",
    "# Uncomment one of these lines if needed:\n",
    "# fix_cudnn_option1()  # Try specific PyTorch version\n",
    "# fix_cudnn_option2()  # Force CPU training\n",
    "# fix_cudnn_option3()  # Install CPU-only PyTorch\n",
    "\n",
    "print(\"💡 If none of these work, restart the runtime and run all cells again.\")\n",
    "print(\"💡 The notebook will automatically adapt to CPU training if GPU fails.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "ilwywgdMHkMv",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Create Project Structure & Configuration Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750704708530,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "W8gW8FooHkMv",
    "outputId": "2c2e34d9-5896-4566-bdee-b67b8505d00f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Created directory: src/models\n",
      "📁 Created directory: src/modules/data_utils\n",
      "📁 Created directory: src/modules/synthetic_data_generator\n",
      "📁 Created directory: src/modules/trainers\n",
      "📁 Created directory: src/fonts\n",
      "📁 Created directory: config\n",
      "📁 Created directory: generated_data\n",
      "📁 Created directory: training_output\n",
      "📁 Created directory: docs\n",
      "✅ Project structure created!\n"
     ]
    }
   ],
   "source": [
    "# Create essential project directories and files\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Create directory structure\n",
    "directories = [\n",
    "    'src/models',\n",
    "    'src/modules/data_utils',\n",
    "    'src/modules/synthetic_data_generator',\n",
    "    'src/modules/trainers',\n",
    "    'src/fonts',\n",
    "    'config',\n",
    "    'generated_data',\n",
    "    'training_output',\n",
    "    'docs'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"📁 Created directory: {directory}\")\n",
    "\n",
    "print(\"✅ Project structure created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750704708536,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "tuI8IeQDHkMv",
    "outputId": "a289c469-0283-4966-f593-169642bbac99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model configuration created!\n"
     ]
    }
   ],
   "source": [
    "# Create model configuration file\n",
    "model_config = {\n",
    "    'model': {\n",
    "        'name': 'khmer_digits_ocr',\n",
    "        'architecture': 'cnn_rnn_attention',\n",
    "        'input': {\n",
    "            'image_size': [128, 64],\n",
    "            'channels': 3,\n",
    "            'normalization': {\n",
    "                'mean': [0.485, 0.456, 0.406],\n",
    "                'std': [0.229, 0.224, 0.225]\n",
    "            }\n",
    "        },\n",
    "        'characters': {\n",
    "            'khmer_digits': [\"០\", \"១\", \"២\", \"៣\", \"៤\", \"៥\", \"៦\", \"៧\", \"៨\", \"៩\"],\n",
    "            'special_tokens': [\"<EOS>\", \"<PAD>\", \"<BLANK>\"],\n",
    "            'total_classes': 13,\n",
    "            'max_sequence_length': 8\n",
    "        },\n",
    "        'cnn': {\n",
    "            'type': 'resnet18',\n",
    "            'pretrained': True,\n",
    "            'feature_size': 512\n",
    "        },\n",
    "        'rnn': {\n",
    "            'encoder': {\n",
    "                'type': 'bidirectional_lstm',\n",
    "                'hidden_size': 256,\n",
    "                'num_layers': 2,\n",
    "                'dropout': 0.1\n",
    "            },\n",
    "            'decoder': {\n",
    "                'type': 'lstm',\n",
    "                'hidden_size': 256,\n",
    "                'num_layers': 1,\n",
    "                'dropout': 0.1\n",
    "            },\n",
    "            'attention': {\n",
    "                'type': 'bahdanau',\n",
    "                'hidden_size': 256\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save model configuration\n",
    "with open('config/model_config.yaml', 'w') as f:\n",
    "    yaml.dump(model_config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(\"✅ Model configuration created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1750704708580,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "UUyzNZTMHkMw",
    "outputId": "4825f61e-6c37-4a91-f61c-8475cb3231f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Configuring for CUDA training\n",
      "📊 Batch size multiplier: 4x\n",
      "✅ Hyperparameter configuration created!\n",
      "📊 Number of experiments: 3\n"
     ]
    }
   ],
   "source": [
    "# Create adaptive hyperparameter tuning configuration\n",
    "# Adjust settings based on available device\n",
    "try:\n",
    "    use_gpu = device_preference == 'cuda'\n",
    "except NameError:\n",
    "    # Fallback if device_preference not set\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    device_preference = 'cuda' if use_gpu else 'cpu'\n",
    "\n",
    "batch_size_multiplier = 4 if use_gpu else 1  # Reduce batch sizes for CPU\n",
    "num_workers = 2 if use_gpu else 0  # Disable multiprocessing for CPU\n",
    "\n",
    "print(f\"🎯 Configuring for {device_preference.upper()} training\")\n",
    "print(f\"📊 Batch size multiplier: {batch_size_multiplier}x\")\n",
    "\n",
    "hyperparameter_config = {\n",
    "    'base_config': {\n",
    "        'data': {\n",
    "            'metadata_path': 'generated_data/metadata.yaml',\n",
    "            'train_split': 'train',\n",
    "            'val_split': 'val',\n",
    "            'num_workers': num_workers,\n",
    "            'pin_memory': use_gpu,\n",
    "            'augmentation': True\n",
    "        },\n",
    "        'training': {\n",
    "            'device': device_preference,\n",
    "            'mixed_precision': use_gpu and torch.cuda.is_available(),\n",
    "            'gradient_clip_norm': 1.0,\n",
    "            'log_every_n_steps': 25,\n",
    "            'save_every_n_epochs': 5,\n",
    "            'keep_n_checkpoints': 3,\n",
    "            'use_tensorboard': True\n",
    "        },\n",
    "        'early_stopping': {\n",
    "            'patience': 8,\n",
    "            'min_delta': 0.001,\n",
    "            'monitor': 'val_char_accuracy',\n",
    "            'mode': 'max'\n",
    "        }\n",
    "    },\n",
    "    'experiments': {\n",
    "        'baseline_gpu_optimized': {\n",
    "            'experiment_name': 'baseline_gpu_optimized',\n",
    "            'model': {\n",
    "                'name': 'medium',\n",
    "                'config_path': 'config/model_config.yaml'\n",
    "            },\n",
    "            'training': {\n",
    "                'batch_size': 32 * batch_size_multiplier,  # Adaptive batch size\n",
    "                'learning_rate': 0.002,\n",
    "                'weight_decay': 0.0001,\n",
    "                'num_epochs': 30 if use_gpu else 15,  # Fewer epochs for CPU\n",
    "                'loss_type': 'crossentropy',\n",
    "                'label_smoothing': 0.1\n",
    "            },\n",
    "            'optimizer': {\n",
    "                'type': 'adamw',\n",
    "                'betas': [0.9, 0.999]\n",
    "            },\n",
    "            'scheduler': {\n",
    "                'type': 'cosine',\n",
    "                'warmup_epochs': 3,\n",
    "                'min_lr': 1e-6\n",
    "            }\n",
    "        },\n",
    "        'aggressive_learning_gpu': {\n",
    "            'experiment_name': 'aggressive_learning_gpu',\n",
    "            'model': {\n",
    "                'name': 'medium',\n",
    "                'config_path': 'config/model_config.yaml'\n",
    "            },\n",
    "            'training': {\n",
    "                'batch_size': 64 * batch_size_multiplier,  # Adaptive batch size\n",
    "                'learning_rate': 0.003,\n",
    "                'weight_decay': 0.0002,\n",
    "                'num_epochs': 25 if use_gpu else 12,  # Fewer epochs for CPU\n",
    "                'loss_type': 'crossentropy',\n",
    "                'label_smoothing': 0.15\n",
    "            },\n",
    "            'optimizer': {\n",
    "                'type': 'adamw',\n",
    "                'betas': [0.9, 0.999]\n",
    "            },\n",
    "            'scheduler': {\n",
    "                'type': 'steplr',\n",
    "                'step_size': 8,\n",
    "                'gamma': 0.5\n",
    "            }\n",
    "        },\n",
    "        'large_model_gpu': {\n",
    "            'experiment_name': 'large_model_gpu',\n",
    "            'model': {\n",
    "                'name': 'large',\n",
    "                'config_path': 'config/model_config.yaml'\n",
    "            },\n",
    "            'training': {\n",
    "                'batch_size': 16 * batch_size_multiplier,  # Smaller batch for large model\n",
    "                'learning_rate': 0.0008,\n",
    "                'weight_decay': 0.0005,\n",
    "                'num_epochs': 25 if use_gpu else 10,  # Fewer epochs for CPU\n",
    "                'loss_type': 'crossentropy',\n",
    "                'label_smoothing': 0.2\n",
    "            },\n",
    "            'optimizer': {\n",
    "                'type': 'adamw',\n",
    "                'betas': [0.9, 0.999]\n",
    "            },\n",
    "            'scheduler': {\n",
    "                'type': 'cosine',\n",
    "                'warmup_epochs': 2,\n",
    "                'min_lr': 1e-6\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save hyperparameter configuration\n",
    "with open('config/phase3_colab_configs.yaml', 'w') as f:\n",
    "    yaml.dump(hyperparameter_config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(\"✅ Hyperparameter configuration created!\")\n",
    "print(f\"📊 Number of experiments: {len(hyperparameter_config['experiments'])}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "0Lwm2tP1HkMw",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Setup Khmer Fonts & Create Module Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1750704708592,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "Faopkp03HkMw",
    "outputId": "f31f7faf-ef71-4fc0-eebc-ddec26bacc4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Downloading Khmer fonts...\n",
      "✅ Font already exists: KhmerOS.ttf\n",
      "📝 Available fonts: ['KhmerOSsiemreap.ttf', 'KhmerOSbokor.ttf', 'KhmerOSmuollight.ttf', 'KhmerOSmuol.ttf', 'KhmerOSfasthand.ttf', 'KhmerOS.ttf', 'KhmerOSbattambang.ttf', 'KhmerOSmetalchrieng.ttf']\n"
     ]
    }
   ],
   "source": [
    "# Download Khmer fonts for data generation\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Create fonts directory\n",
    "os.makedirs('src/fonts', exist_ok=True)\n",
    "\n",
    "# Download a basic Khmer font (you may need to add more fonts)\n",
    "font_urls = {\n",
    "    'KhmerOS.ttf': 'https://github.com/google/fonts/raw/main/ofl/khmeros/KhmerOS.ttf'\n",
    "}\n",
    "\n",
    "print(\"📝 Downloading Khmer fonts...\")\n",
    "for font_name, url in font_urls.items():\n",
    "    font_path = f'src/fonts/{font_name}'\n",
    "    if not os.path.exists(font_path):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, font_path)\n",
    "            print(f\"✅ Downloaded {font_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to download {font_name}: {e}\")\n",
    "            # Create a dummy font file for testing\n",
    "            with open(font_path, 'w') as f:\n",
    "                f.write(\"dummy font file\")\n",
    "            print(f\"⚠️ Created dummy font file: {font_name}\")\n",
    "    else:\n",
    "        print(f\"✅ Font already exists: {font_name}\")\n",
    "\n",
    "# List fonts\n",
    "fonts = os.listdir('src/fonts')\n",
    "print(f\"📝 Available fonts: {fonts}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cBAeyPd7HkMx",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Create Core Module Files\n",
    "\n",
    "Since we're starting fresh, we need to create the essential module files for our OCR system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1750704708652,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "d9RtL5s9HkMx",
    "outputId": "7f87bef0-4443-4ace-b88a-6a1fe8874825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created src/__init__.py\n",
      "✅ Created src/models/__init__.py\n",
      "✅ Created src/modules/__init__.py\n",
      "✅ Created src/modules/data_utils/__init__.py\n",
      "✅ Created src/modules/synthetic_data_generator/__init__.py\n",
      "✅ Created src/modules/trainers/__init__.py\n",
      "✅ Module structure created!\n"
     ]
    }
   ],
   "source": [
    "# Create essential __init__.py files\n",
    "init_files = [\n",
    "    'src/__init__.py',\n",
    "    'src/models/__init__.py',\n",
    "    'src/modules/__init__.py',\n",
    "    'src/modules/data_utils/__init__.py',\n",
    "    'src/modules/synthetic_data_generator/__init__.py',\n",
    "    'src/modules/trainers/__init__.py'\n",
    "]\n",
    "\n",
    "for init_file in init_files:\n",
    "    with open(init_file, 'w') as f:\n",
    "        f.write('\"\"\"Module initialization.\"\"\"\\n')\n",
    "    print(f\"✅ Created {init_file}\")\n",
    "\n",
    "print(\"✅ Module structure created!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "TIZgOMw7HkMx",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Simplified Data Generation & Dataset Creation\n",
    "\n",
    "For this Colab demo, we'll create a simplified version of the data generation system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5678,
     "status": "ok",
     "timestamp": 1750704714333,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "35vz4icHHkMx",
    "outputId": "afc5f749-320b-4c58-af01-9b1a7ce88f3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data generator initialized\n",
      "📊 Character set size: 13\n",
      "🔄 Generating 2000 samples...\n",
      "  Generated 100/2000 samples\n",
      "  Generated 200/2000 samples\n",
      "  Generated 300/2000 samples\n",
      "  Generated 400/2000 samples\n",
      "  Generated 500/2000 samples\n",
      "  Generated 600/2000 samples\n",
      "  Generated 700/2000 samples\n",
      "  Generated 800/2000 samples\n",
      "  Generated 900/2000 samples\n",
      "  Generated 1000/2000 samples\n",
      "  Generated 1100/2000 samples\n",
      "  Generated 1200/2000 samples\n",
      "  Generated 1300/2000 samples\n",
      "  Generated 1400/2000 samples\n",
      "  Generated 1500/2000 samples\n",
      "  Generated 1600/2000 samples\n",
      "  Generated 1700/2000 samples\n",
      "  Generated 1800/2000 samples\n",
      "  Generated 1900/2000 samples\n",
      "  Generated 2000/2000 samples\n",
      "✅ Dataset generated successfully!\n",
      "📊 Train samples: 1600\n",
      "📊 Validation samples: 400\n",
      "📄 Metadata saved to: generated_data/metadata.yaml\n",
      "✅ Data generation completed!\n"
     ]
    }
   ],
   "source": [
    "# Simplified data generation for Colab\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "class SimplifiedDataGenerator:\n",
    "    \"\"\"Simplified data generator for Colab environment.\"\"\"\n",
    "\n",
    "    def __init__(self, fonts_dir='src/fonts', output_dir='generated_data'):\n",
    "        self.fonts_dir = Path(fonts_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Khmer digits\n",
    "        self.khmer_digits = [\"០\", \"១\", \"២\", \"៣\", \"៤\", \"៥\", \"៦\", \"៧\", \"៨\", \"៩\"]\n",
    "        self.special_tokens = [\"<EOS>\", \"<PAD>\", \"<BLANK>\"]\n",
    "\n",
    "        # Create character mappings\n",
    "        all_chars = self.khmer_digits + self.special_tokens\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(all_chars)}\n",
    "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
    "\n",
    "        print(f\"✅ Data generator initialized\")\n",
    "        print(f\"📊 Character set size: {len(all_chars)}\")\n",
    "\n",
    "    def generate_sample_image(self, text, size=(128, 64)):\n",
    "        \"\"\"Generate a simple text image.\"\"\"\n",
    "        # Create image with white background\n",
    "        img = Image.new('RGB', size, 'white')\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        # Try to use downloaded font, fallback to default\n",
    "        try:\n",
    "            font_files = list(self.fonts_dir.glob('*.ttf'))\n",
    "            if font_files:\n",
    "                font = ImageFont.truetype(str(font_files[0]), 24)\n",
    "            else:\n",
    "                font = ImageFont.load_default()\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Calculate text position (center)\n",
    "        bbox = draw.textbbox((0, 0), text, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "        x = (size[0] - text_width) // 2\n",
    "        y = (size[1] - text_height) // 2\n",
    "\n",
    "        # Draw text\n",
    "        draw.text((x, y), text, fill='black', font=font)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def generate_dataset(self, num_samples=1000, train_split=0.8):\n",
    "        \"\"\"Generate a simple dataset.\"\"\"\n",
    "        print(f\"🔄 Generating {num_samples} samples...\")\n",
    "\n",
    "        samples = []\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            # Generate random sequence length (1-5 digits)\n",
    "            seq_length = random.randint(1, 5)\n",
    "\n",
    "            # Generate random digit sequence\n",
    "            digits = [random.choice(self.khmer_digits) for _ in range(seq_length)]\n",
    "            text = ''.join(digits)\n",
    "\n",
    "            # Generate image\n",
    "            img = self.generate_sample_image(text)\n",
    "\n",
    "            # Save image\n",
    "            img_filename = f\"sample_{i:06d}.png\"\n",
    "            img_path = self.output_dir / img_filename\n",
    "            img.save(img_path)\n",
    "\n",
    "            # Create sample metadata\n",
    "            sample = {\n",
    "                'image_path': str(img_path),\n",
    "                'text': text,\n",
    "                'char_indices': [self.char_to_idx[char] for char in text],\n",
    "                'sequence_length': len(text)\n",
    "            }\n",
    "            samples.append(sample)\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"  Generated {i + 1}/{num_samples} samples\")\n",
    "\n",
    "        # Split data\n",
    "        split_idx = int(len(samples) * train_split)\n",
    "        train_samples = samples[:split_idx]\n",
    "        val_samples = samples[split_idx:]\n",
    "\n",
    "        # Create metadata\n",
    "        metadata = {\n",
    "            'dataset_info': {\n",
    "                'total_samples': len(samples),\n",
    "                'train_samples': len(train_samples),\n",
    "                'val_samples': len(val_samples),\n",
    "                'char_to_idx': self.char_to_idx,\n",
    "                'idx_to_char': self.idx_to_char,\n",
    "                'max_sequence_length': max(s['sequence_length'] for s in samples)\n",
    "            },\n",
    "            'splits': {\n",
    "                'train': train_samples,\n",
    "                'val': val_samples\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Save metadata\n",
    "        metadata_path = self.output_dir / 'metadata.yaml'\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            yaml.dump(metadata, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "        print(f\"✅ Dataset generated successfully!\")\n",
    "        print(f\"📊 Train samples: {len(train_samples)}\")\n",
    "        print(f\"📊 Validation samples: {len(val_samples)}\")\n",
    "        print(f\"📄 Metadata saved to: {metadata_path}\")\n",
    "\n",
    "        return metadata\n",
    "\n",
    "# Generate dataset\n",
    "generator = SimplifiedDataGenerator()\n",
    "metadata = generator.generate_dataset(num_samples=2000, train_split=0.8)\n",
    "\n",
    "print(\"✅ Data generation completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Uih-zAk8HkMy",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Create Simplified OCR Model & Training Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13946,
     "status": "ok",
     "timestamp": 1750704728281,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "NR7v8JqUHkMy",
    "outputId": "c5c7ec02-c7c7-406e-e6e4-aa179a4ac3ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and dataset classes created!\n"
     ]
    }
   ],
   "source": [
    "# Simplified OCR Model for Colab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import yaml\n",
    "\n",
    "class SimpleOCRModel(nn.Module):\n",
    "    \"\"\"Simplified OCR model for Khmer digits.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, max_sequence_length, model_size='medium'):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "\n",
    "        # Model size configurations\n",
    "        size_configs = {\n",
    "            'small': {'cnn_features': 128, 'rnn_hidden': 128},\n",
    "            'medium': {'cnn_features': 256, 'rnn_hidden': 256},\n",
    "            'large': {'cnn_features': 512, 'rnn_hidden': 512}\n",
    "        }\n",
    "        config = size_configs[model_size]\n",
    "\n",
    "        # Simple CNN backbone\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, config['cnn_features'], 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4, 8))\n",
    "        )\n",
    "\n",
    "        # RNN for sequence modeling\n",
    "        self.rnn = nn.LSTM(\n",
    "            config['cnn_features'],\n",
    "            config['rnn_hidden'],\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(config['rnn_hidden'] * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # CNN feature extraction\n",
    "        features = self.cnn(x)  # [B, C, H, W]\n",
    "\n",
    "        # Reshape for RNN\n",
    "        features = features.view(batch_size, features.size(1), -1)  # [B, C, H*W]\n",
    "        features = features.permute(0, 2, 1)  # [B, H*W, C]\n",
    "\n",
    "        # RNN\n",
    "        rnn_out, _ = self.rnn(features)  # [B, seq_len, hidden*2]\n",
    "\n",
    "        # Apply dropout and classification\n",
    "        rnn_out = self.dropout(rnn_out)\n",
    "        logits = self.classifier(rnn_out)  # [B, seq_len, vocab_size]\n",
    "\n",
    "        return logits\n",
    "\n",
    "class KhmerDataset(Dataset):\n",
    "    \"\"\"Simple dataset for Khmer digits.\"\"\"\n",
    "\n",
    "    def __init__(self, samples, char_to_idx, max_seq_len, transform=None):\n",
    "        self.samples = samples\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(sample['image_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Prepare target sequence\n",
    "        text = sample['text']\n",
    "        target = [self.char_to_idx[char] for char in text]\n",
    "        target.append(self.char_to_idx['<EOS>'])  # Add EOS token\n",
    "\n",
    "        # Pad sequence\n",
    "        while len(target) < self.max_seq_len:\n",
    "            target.append(self.char_to_idx['<PAD>'])\n",
    "\n",
    "        target = torch.tensor(target[:self.max_seq_len], dtype=torch.long)\n",
    "\n",
    "        return image, target, len(text) + 1  # +1 for EOS\n",
    "\n",
    "def create_model(model_size, vocab_size, max_sequence_length):\n",
    "    \"\"\"Create model based on configuration.\"\"\"\n",
    "    return SimpleOCRModel(vocab_size, max_sequence_length, model_size)\n",
    "\n",
    "print(\"✅ Model and dataset classes created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1750704728325,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "VUXPi2u5HkMy",
    "outputId": "e8c2b94b-ef01-4ac1-aa89-f35d4fd08637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trainer class created!\n"
     ]
    }
   ],
   "source": [
    "# Simplified Trainer for Hyperparameter Tuning\n",
    "import time\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "class SimpleTrainer:\n",
    "    \"\"\"Simplified trainer for hyperparameter tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, model, train_loader, val_loader, config, device):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "\n",
    "        # Setup optimizer\n",
    "        if config['optimizer']['type'] == 'adamw':\n",
    "            self.optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=config['training']['learning_rate'],\n",
    "                weight_decay=config['training']['weight_decay'],\n",
    "                betas=config['optimizer']['betas']\n",
    "            )\n",
    "        else:\n",
    "            self.optimizer = torch.optim.Adam(\n",
    "                model.parameters(),\n",
    "                lr=config['training']['learning_rate'],\n",
    "                weight_decay=config['training']['weight_decay']\n",
    "            )\n",
    "\n",
    "        # Setup scheduler\n",
    "        if config['scheduler']['type'] == 'cosine':\n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                self.optimizer,\n",
    "                T_max=config['training']['num_epochs'],\n",
    "                eta_min=config['scheduler']['min_lr']\n",
    "            )\n",
    "        elif config['scheduler']['type'] == 'steplr':\n",
    "            self.scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                self.optimizer,\n",
    "                step_size=config['scheduler']['step_size'],\n",
    "                gamma=config['scheduler']['gamma']\n",
    "            )\n",
    "        else:\n",
    "            self.scheduler = None\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=metadata['dataset_info']['char_to_idx']['<PAD>'])\n",
    "\n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_char_accuracy': [],\n",
    "            'val_seq_accuracy': []\n",
    "        }\n",
    "\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def calculate_accuracy(self, outputs, targets, lengths):\n",
    "        \"\"\"Calculate character and sequence accuracy.\"\"\"\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        char_correct = 0\n",
    "        char_total = 0\n",
    "        seq_correct = 0\n",
    "\n",
    "        for pred, target, length in zip(predictions, targets, lengths):\n",
    "            # Character accuracy\n",
    "            pred_chars = pred[:length]\n",
    "            target_chars = target[:length]\n",
    "            char_correct += (pred_chars == target_chars).sum().item()\n",
    "            char_total += length\n",
    "\n",
    "            # Sequence accuracy\n",
    "            if torch.equal(pred_chars, target_chars):\n",
    "                seq_correct += 1\n",
    "\n",
    "        char_accuracy = char_correct / char_total if char_total > 0 else 0\n",
    "        seq_accuracy = seq_correct / len(lengths)\n",
    "\n",
    "        return char_accuracy, seq_accuracy\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for images, targets, lengths in self.train_loader:\n",
    "            images = images.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(images)\n",
    "\n",
    "            # Reshape for loss computation\n",
    "            outputs = outputs.view(-1, outputs.size(-1))\n",
    "            targets = targets.view(-1)\n",
    "\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        return total_loss / num_batches\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Validate the model.\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_char_acc = []\n",
    "        all_seq_acc = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets, lengths in self.val_loader:\n",
    "                images = images.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "\n",
    "                outputs = self.model(images)\n",
    "\n",
    "                # Calculate loss\n",
    "                outputs_flat = outputs.view(-1, outputs.size(-1))\n",
    "                targets_flat = targets.view(-1)\n",
    "                loss = self.criterion(outputs_flat, targets_flat)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                char_acc, seq_acc = self.calculate_accuracy(outputs, targets, lengths)\n",
    "                all_char_acc.append(char_acc)\n",
    "                all_seq_acc.append(seq_acc)\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        avg_char_acc = sum(all_char_acc) / len(all_char_acc)\n",
    "        avg_seq_acc = sum(all_seq_acc) / len(all_seq_acc)\n",
    "\n",
    "        return avg_loss, avg_char_acc, avg_seq_acc\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Full training loop.\"\"\"\n",
    "        print(f\"🚀 Starting training: {self.config['experiment_name']}\")\n",
    "\n",
    "        for epoch in range(self.config['training']['num_epochs']):\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Train\n",
    "            train_loss = self.train_epoch()\n",
    "\n",
    "            # Validate\n",
    "            val_loss, val_char_acc, val_seq_acc = self.validate()\n",
    "\n",
    "            # Update scheduler\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            # Update history\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_char_accuracy'].append(val_char_acc)\n",
    "            self.history['val_seq_accuracy'].append(val_seq_acc)\n",
    "\n",
    "            # Save best model\n",
    "            if val_char_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_char_acc\n",
    "                self.best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.config['training']['num_epochs']} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | \"\n",
    "                  f\"Val Char Acc: {val_char_acc:.4f} | \"\n",
    "                  f\"Val Seq Acc: {val_seq_acc:.4f} | \"\n",
    "                  f\"Time: {epoch_time:.1f}s\")\n",
    "\n",
    "            # Early stopping check\n",
    "            if len(self.history['val_char_accuracy']) >= self.config['early_stopping']['patience']:\n",
    "                recent_accs = self.history['val_char_accuracy'][-self.config['early_stopping']['patience']:]\n",
    "                if max(recent_accs) - min(recent_accs) < self.config['early_stopping']['min_delta']:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        return self.history\n",
    "\n",
    "print(\"✅ Trainer class created!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "mtEb76PcHkMz",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🔧 Fix for Sequence Length Mismatch\n",
    "\n",
    "The error occurs because the model outputs a different sequence length than the targets. Let's fix this issue:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1750704728345,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "Q5frxGrLHkMz",
    "outputId": "60a7b519-8ba1-4c7d-da02-9cce044eab4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Creating fixed model and trainer classes...\n",
      "✅ Fixed model and trainer classes created!\n"
     ]
    }
   ],
   "source": [
    "# Fixed Model and Trainer Classes\n",
    "print(\"🔧 Creating fixed model and trainer classes...\")\n",
    "\n",
    "class FixedSimpleOCRModel(nn.Module):\n",
    "    \"\"\"Fixed OCR model with proper sequence length handling.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, max_sequence_length, model_size='medium'):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "\n",
    "        # Model size configurations\n",
    "        size_configs = {\n",
    "            'small': {'cnn_features': 128, 'rnn_hidden': 128},\n",
    "            'medium': {'cnn_features': 256, 'rnn_hidden': 256},\n",
    "            'large': {'cnn_features': 512, 'rnn_hidden': 512}\n",
    "        }\n",
    "        config = size_configs[model_size]\n",
    "\n",
    "        # CNN backbone that outputs exactly max_sequence_length features\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, config['cnn_features'], 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, max_sequence_length))  # Force exact sequence length\n",
    "        )\n",
    "\n",
    "        # RNN for sequence modeling\n",
    "        self.rnn = nn.LSTM(\n",
    "            config['cnn_features'],\n",
    "            config['rnn_hidden'],\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(config['rnn_hidden'] * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # CNN feature extraction\n",
    "        features = self.cnn(x)  # [B, C, 1, max_seq_len]\n",
    "\n",
    "        # Reshape for RNN: [B, max_seq_len, C]\n",
    "        features = features.squeeze(2).permute(0, 2, 1)  # [B, max_seq_len, C]\n",
    "\n",
    "        # RNN\n",
    "        rnn_out, _ = self.rnn(features)  # [B, max_seq_len, hidden*2]\n",
    "\n",
    "        # Apply dropout and classification\n",
    "        rnn_out = self.dropout(rnn_out)\n",
    "        logits = self.classifier(rnn_out)  # [B, max_seq_len, vocab_size]\n",
    "\n",
    "        return logits\n",
    "\n",
    "class FixedSimpleTrainer:\n",
    "    \"\"\"Fixed trainer with proper sequence length handling.\"\"\"\n",
    "\n",
    "    def __init__(self, model, train_loader, val_loader, config, device, char_to_idx):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.char_to_idx = char_to_idx\n",
    "\n",
    "        # Setup optimizer\n",
    "        if config['optimizer']['type'] == 'adamw':\n",
    "            self.optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=config['training']['learning_rate'],\n",
    "                weight_decay=config['training']['weight_decay'],\n",
    "                betas=config['optimizer']['betas']\n",
    "            )\n",
    "        else:\n",
    "            self.optimizer = torch.optim.Adam(\n",
    "                model.parameters(),\n",
    "                lr=config['training']['learning_rate'],\n",
    "                weight_decay=config['training']['weight_decay']\n",
    "            )\n",
    "\n",
    "        # Setup scheduler\n",
    "        if config['scheduler']['type'] == 'cosine':\n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                self.optimizer,\n",
    "                T_max=config['training']['num_epochs'],\n",
    "                eta_min=config['scheduler']['min_lr']\n",
    "            )\n",
    "        elif config['scheduler']['type'] == 'steplr':\n",
    "            self.scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                self.optimizer,\n",
    "                step_size=config['scheduler']['step_size'],\n",
    "                gamma=config['scheduler']['gamma']\n",
    "            )\n",
    "        else:\n",
    "            self.scheduler = None\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=char_to_idx['<PAD>'])\n",
    "\n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_char_accuracy': [],\n",
    "            'val_seq_accuracy': []\n",
    "        }\n",
    "\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def calculate_accuracy(self, outputs, targets, lengths):\n",
    "        \"\"\"Calculate character and sequence accuracy.\"\"\"\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        char_correct = 0\n",
    "        char_total = 0\n",
    "        seq_correct = 0\n",
    "\n",
    "        for pred, target, length in zip(predictions, targets, lengths):\n",
    "            # Character accuracy (exclude padding)\n",
    "            pred_chars = pred[:length]\n",
    "            target_chars = target[:length]\n",
    "            char_correct += (pred_chars == target_chars).sum().item()\n",
    "            char_total += length\n",
    "\n",
    "            # Sequence accuracy\n",
    "            if torch.equal(pred_chars, target_chars):\n",
    "                seq_correct += 1\n",
    "\n",
    "        char_accuracy = char_correct / char_total if char_total > 0 else 0\n",
    "        seq_accuracy = seq_correct / len(lengths)\n",
    "\n",
    "        return char_accuracy, seq_accuracy\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for images, targets, lengths in self.train_loader:\n",
    "            images = images.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(images)  # [B, max_seq_len, vocab_size]\n",
    "\n",
    "            # Now both outputs and targets have the same sequence length\n",
    "            # Reshape for loss computation\n",
    "            outputs = outputs.view(-1, outputs.size(-1))  # [B*max_seq_len, vocab_size]\n",
    "            targets = targets.view(-1)  # [B*max_seq_len]\n",
    "\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        return total_loss / num_batches\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Validate the model.\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_char_acc = []\n",
    "        all_seq_acc = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets, lengths in self.val_loader:\n",
    "                images = images.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "\n",
    "                outputs = self.model(images)\n",
    "\n",
    "                # Calculate loss\n",
    "                outputs_flat = outputs.view(-1, outputs.size(-1))\n",
    "                targets_flat = targets.view(-1)\n",
    "                loss = self.criterion(outputs_flat, targets_flat)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                char_acc, seq_acc = self.calculate_accuracy(outputs, targets, lengths)\n",
    "                all_char_acc.append(char_acc)\n",
    "                all_seq_acc.append(seq_acc)\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        avg_char_acc = sum(all_char_acc) / len(all_char_acc) if all_char_acc else 0\n",
    "        avg_seq_acc = sum(all_seq_acc) / len(all_seq_acc) if all_seq_acc else 0\n",
    "\n",
    "        return avg_loss, avg_char_acc, avg_seq_acc\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Full training loop.\"\"\"\n",
    "        print(f\"🚀 Starting training: {self.config['experiment_name']}\")\n",
    "\n",
    "        for epoch in range(self.config['training']['num_epochs']):\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Train\n",
    "            train_loss = self.train_epoch()\n",
    "\n",
    "            # Validate\n",
    "            val_loss, val_char_acc, val_seq_acc = self.validate()\n",
    "\n",
    "            # Update scheduler\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            # Update history\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_char_accuracy'].append(val_char_acc)\n",
    "            self.history['val_seq_accuracy'].append(val_seq_acc)\n",
    "\n",
    "            # Save best model\n",
    "            if val_char_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_char_acc\n",
    "                self.best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.config['training']['num_epochs']} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | \"\n",
    "                  f\"Val Char Acc: {val_char_acc:.4f} | \"\n",
    "                  f\"Val Seq Acc: {val_seq_acc:.4f} | \"\n",
    "                  f\"Time: {epoch_time:.1f}s\")\n",
    "\n",
    "            # Early stopping check\n",
    "            if len(self.history['val_char_accuracy']) >= self.config['early_stopping']['patience']:\n",
    "                recent_accs = self.history['val_char_accuracy'][-self.config['early_stopping']['patience']:]\n",
    "                if max(recent_accs) - min(recent_accs) < self.config['early_stopping']['min_delta']:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        return self.history\n",
    "\n",
    "# Update create_model function\n",
    "def create_model_fixed(model_size, vocab_size, max_sequence_length):\n",
    "    \"\"\"Create fixed model based on configuration.\"\"\"\n",
    "    return FixedSimpleOCRModel(vocab_size, max_sequence_length, model_size)\n",
    "\n",
    "print(\"✅ Fixed model and trainer classes created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "error",
     "timestamp": 1750704728360,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "M6xi_rDVHkM0",
    "outputId": "5d65797e-7e50-4d96-f122-de57ef38bd26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving results to Google Drive...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fixed_tuner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-16-3125357819.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save results and generate summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"💾 Saving results to Google Drive...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate summary report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fixed_tuner' is not defined"
     ]
    }
   ],
   "source": [
    "# Save results and generate summary\n",
    "print(\"💾 Saving results to Google Drive...\")\n",
    "results_file = fixed_tuner.save_results()\n",
    "\n",
    "# Generate summary report\n",
    "summary = fixed_tuner.generate_summary()\n",
    "print(\"\\n📊 EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    elif key.endswith('_time'):\n",
    "        print(f\"{key}: {value/60:.1f} minutes\" if isinstance(value, (int, float)) else f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\n📁 Results saved to Google Drive:\")\n",
    "print(f\"  • Detailed results: {results_file}\")\n",
    "\n",
    "# Show final status\n",
    "completed_experiments = [r for r in fixed_tuner.results if r.get('status') == 'completed']\n",
    "failed_experiments = [r for r in fixed_tuner.results if r.get('status') == 'failed']\n",
    "\n",
    "print(f\"\\n🎯 FINAL STATUS:\")\n",
    "print(f\"✅ Completed experiments: {len(completed_experiments)}\")\n",
    "print(f\"❌ Failed experiments: {len(failed_experiments)}\")\n",
    "\n",
    "if completed_experiments:\n",
    "    print(f\"\\n🏆 BEST PERFORMING MODEL:\")\n",
    "    best = fixed_tuner.best_result\n",
    "    print(f\"  • Experiment: {best['experiment_name']}\")\n",
    "    print(f\"  • Character accuracy: {best['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"  • Sequence accuracy: {best['best_val_seq_accuracy']:.4f}\")\n",
    "    print(f\"  • Training time: {best['training_time']/60:.1f} minutes\")\n",
    "    print(f\"  • Model saved at: {best.get('model_path', 'N/A')}\")\n",
    "\n",
    "print(f\"\\n✅ Hyperparameter tuning completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "wO6zRb0eHkM0",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🔧 Quick Fix for JSON Serialization Error\n",
    "\n",
    "If you encountered the \"Object of type Tensor is not JSON serializable\" error, run the cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54320,
     "status": "aborted",
     "timestamp": 1750704728362,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "pK5k0psMHkM0"
   },
   "outputs": [],
   "source": [
    "# Quick fix for tensor serialization issue\n",
    "def convert_tensors_to_python(obj):\n",
    "    \"\"\"Recursively convert tensors to Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.item() if obj.numel() == 1 else obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_tensors_to_python(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_tensors_to_python(item) for item in obj]\n",
    "    elif isinstance(obj, (int, float, str, bool, type(None))):\n",
    "        return obj\n",
    "    else:\n",
    "        # For other types, try to convert to string\n",
    "        return str(obj)\n",
    "\n",
    "# Save results with tensor conversion\n",
    "print(\"💾 Saving results to Google Drive (with tensor conversion)...\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Convert tensors to Python types for JSON serialization\n",
    "serializable_results = convert_tensors_to_python({\n",
    "    'timestamp': timestamp,\n",
    "    'device': str(fixed_tuner.device),\n",
    "    'dataset_info': fixed_tuner.metadata['dataset_info'],\n",
    "    'best_result': fixed_tuner.best_result,\n",
    "    'all_results': fixed_tuner.results,\n",
    "    'summary': fixed_tuner.generate_summary()\n",
    "})\n",
    "\n",
    "# Save detailed results\n",
    "results_file = f\"{project_drive_path}/results/hyperparameter_tuning_results_{timestamp}.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(serializable_results, f, indent=2)\n",
    "\n",
    "print(f\"✅ Results saved successfully to: {results_file}\")\n",
    "\n",
    "# Generate summary report\n",
    "summary = fixed_tuner.generate_summary()\n",
    "print(\"\\n📊 EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    elif key.endswith('_time'):\n",
    "        print(f\"{key}: {value/60:.1f} minutes\" if isinstance(value, (int, float)) else f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\n📁 Results saved to Google Drive:\")\n",
    "print(f\"  • Detailed results: {results_file}\")\n",
    "\n",
    "# Show final status\n",
    "completed_experiments = [r for r in fixed_tuner.results if r.get('status') == 'completed']\n",
    "failed_experiments = [r for r in fixed_tuner.results if r.get('status') == 'failed']\n",
    "\n",
    "print(f\"\\n🎯 FINAL STATUS:\")\n",
    "print(f\"✅ Completed experiments: {len(completed_experiments)}\")\n",
    "print(f\"❌ Failed experiments: {len(failed_experiments)}\")\n",
    "\n",
    "if completed_experiments:\n",
    "    print(f\"\\n🏆 BEST PERFORMING MODEL:\")\n",
    "    best = fixed_tuner.best_result\n",
    "    print(f\"  • Experiment: {best['experiment_name']}\")\n",
    "    print(f\"  • Character accuracy: {best['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"  • Sequence accuracy: {best['best_val_seq_accuracy']:.4f}\")\n",
    "    print(f\"  • Training time: {best['training_time']/60:.1f} minutes\")\n",
    "    print(f\"  • Model saved at: {best.get('model_path', 'N/A')}\")\n",
    "\n",
    "    # List all completed experiments\n",
    "    print(f\"\\n📋 ALL COMPLETED EXPERIMENTS:\")\n",
    "    for i, result in enumerate(completed_experiments, 1):\n",
    "        print(f\"  {i}. {result['experiment_name']}\")\n",
    "        print(f\"     - Character accuracy: {result['best_val_char_accuracy']:.4f}\")\n",
    "        print(f\"     - Sequence accuracy: {result['best_val_seq_accuracy']:.4f}\")\n",
    "        print(f\"     - Training time: {result['training_time']/60:.1f} min\")\n",
    "\n",
    "if failed_experiments:\n",
    "    print(f\"\\n❌ FAILED EXPERIMENTS:\")\n",
    "    for result in failed_experiments:\n",
    "        print(f\"  • {result['experiment_name']}: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(f\"\\n✅ Hyperparameter tuning completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "u1WOHmVrHkM0",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🔧 Test Fixed Classes & Run Single Experiment\n",
    "\n",
    "Let's test the fixed classes with a single experiment to verify the sequence length issue is resolved:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1750704728383,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "yRcbcCtkHkM1"
   },
   "outputs": [],
   "source": [
    "# Test the fixed classes with a single experiment\n",
    "print(\"🧪 Testing fixed classes with a single experiment...\")\n",
    "\n",
    "# Load metadata\n",
    "with open('generated_data/metadata.yaml', 'r') as f:\n",
    "    metadata = yaml.safe_load(f)\n",
    "\n",
    "print(f\"📊 Dataset info:\")\n",
    "print(f\"  • Max sequence length: {metadata['dataset_info']['max_sequence_length']}\")\n",
    "print(f\"  • Vocab size: {len(metadata['dataset_info']['char_to_idx'])}\")\n",
    "print(f\"  • Training samples: {metadata['dataset_info']['train_samples']}\")\n",
    "\n",
    "# Create a small test dataset\n",
    "test_dataset = KhmerDataset(\n",
    "    metadata['splits']['train'][:32],  # Use only 32 samples for quick test\n",
    "    metadata['dataset_info']['char_to_idx'],\n",
    "    metadata['dataset_info']['max_sequence_length'] + 1\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Create fixed model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_model = create_model_fixed(\n",
    "    model_size='small',  # Use small model for quick test\n",
    "    vocab_size=len(metadata['dataset_info']['char_to_idx']),\n",
    "    max_sequence_length=metadata['dataset_info']['max_sequence_length'] + 1\n",
    ")\n",
    "\n",
    "print(f\"🔥 Using device: {device}\")\n",
    "print(f\"📏 Model max sequence length: {test_model.max_sequence_length}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_model.to(device)\n",
    "test_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets, lengths in test_loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        print(f\"\\n🔍 Testing batch:\")\n",
    "        print(f\"  • Images shape: {images.shape}\")\n",
    "        print(f\"  • Targets shape: {targets.shape}\")\n",
    "        print(f\"  • Sequence lengths: {lengths.tolist()}\")\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = test_model(images)\n",
    "        print(f\"  • Model outputs shape: {outputs.shape}\")\n",
    "\n",
    "        # Test loss calculation\n",
    "        pad_idx = metadata['dataset_info']['char_to_idx']['<PAD>']\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "        # Reshape for loss\n",
    "        outputs_flat = outputs.view(-1, outputs.size(-1))\n",
    "        targets_flat = targets.view(-1)\n",
    "\n",
    "        print(f\"  • Flattened outputs shape: {outputs_flat.shape}\")\n",
    "        print(f\"  • Flattened targets shape: {targets_flat.shape}\")\n",
    "\n",
    "        # This should work now!\n",
    "        loss = criterion(outputs_flat, targets_flat)\n",
    "        print(f\"  ✅ Loss calculated successfully: {loss.item():.4f}\")\n",
    "\n",
    "        break  # Only test first batch\n",
    "\n",
    "print(\"\\n✅ Fixed classes are working correctly!\")\n",
    "print(\"🚀 You can now run experiments with FixedHyperparameterTuner\")\n",
    "\n",
    "# Clean up\n",
    "del test_model, test_dataset, test_loader\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "mdny79_nHkM1",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🚀 Run Single Experiment with Fixed Classes\n",
    "\n",
    "Now let's run a complete single experiment to verify everything works:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "fmMknSnTHkM1",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🎯 Run All Experiments with Fixed Classes\n",
    "\n",
    "**IMPORTANT**: Make sure to use `FixedHyperparameterTuner` instead of the old `HyperparameterTuner`!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1750704728387,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "7YrFTY-SHkM1"
   },
   "outputs": [],
   "source": [
    "# 🚨 IMPORTANT: Use the FIXED tuner to avoid sequence length errors!\n",
    "print(\"🚀 Starting ALL experiments with FIXED classes...\")\n",
    "print(\"⚠️  This will use FixedHyperparameterTuner (not the old one)\")\n",
    "\n",
    "# Initialize the FIXED tuner (not the old one!)\n",
    "fixed_tuner = FixedHyperparameterTuner()\n",
    "\n",
    "# Define ALL experiment configurations with FIXED settings\n",
    "experiments = {\n",
    "    'baseline_gpu_optimized_fixed': {\n",
    "        'experiment_name': 'baseline_gpu_optimized_fixed',\n",
    "        'model': {\n",
    "            'name': 'medium',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 128,\n",
    "            'learning_rate': 0.002,\n",
    "            'weight_decay': 0.0001,\n",
    "            'num_epochs': 25,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.1\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adamw',\n",
    "            'betas': [0.9, 0.999]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'cosine',\n",
    "            'warmup_epochs': 3,\n",
    "            'min_lr': 1e-6\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'aggressive_learning_fixed': {\n",
    "        'experiment_name': 'aggressive_learning_fixed',\n",
    "        'model': {\n",
    "            'name': 'medium',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 256,\n",
    "            'learning_rate': 0.003,\n",
    "            'weight_decay': 0.00005,\n",
    "            'num_epochs': 25,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.05\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adam',\n",
    "            'betas': [0.9, 0.999]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'step',\n",
    "            'step_size': 8,\n",
    "            'gamma': 0.5\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'large_model_gpu_fixed': {\n",
    "        'experiment_name': 'large_model_gpu_fixed',\n",
    "        'model': {\n",
    "            'name': 'large',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 64,\n",
    "            'learning_rate': 0.0008,\n",
    "            'weight_decay': 0.0003,\n",
    "            'num_epochs': 30,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.15\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adamw',\n",
    "            'betas': [0.9, 0.99]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'cosine',\n",
    "            'warmup_epochs': 5,\n",
    "            'min_lr': 1e-7\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"📋 Will run {len(experiments)} experiments:\")\n",
    "for name in experiments.keys():\n",
    "    print(f\"  • {name}\")\n",
    "\n",
    "# Run all experiments with the FIXED tuner\n",
    "results = fixed_tuner.run_experiments(experiments)\n",
    "\n",
    "print(\"\\n🎉 All experiments completed!\")\n",
    "print(f\"📊 Results summary:\")\n",
    "print(f\"  • Total experiments: {len(results)}\")\n",
    "print(f\"  • Successful: {sum(1 for r in results if r['status'] == 'completed')}\")\n",
    "print(f\"  • Failed: {sum(1 for r in results if r['status'] == 'failed')}\")\n",
    "\n",
    "# Find best result\n",
    "best_result = None\n",
    "for result in results:\n",
    "    if result['status'] == 'completed':\n",
    "        if best_result is None or result['best_val_char_accuracy'] > best_result['best_val_char_accuracy']:\n",
    "            best_result = result\n",
    "\n",
    "if best_result:\n",
    "    print(f\"\\n🏆 Best experiment: {best_result['experiment_name']}\")\n",
    "    print(f\"  • Character accuracy: {best_result['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"  • Sequence accuracy: {best_result['best_val_seq_accuracy']:.4f}\")\n",
    "    print(f\"  • Training time: {best_result['training_time']:.1f} seconds\")\n",
    "else:\n",
    "    print(\"\\n❌ No successful experiments\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "QDJzy1OPHkM2",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🔧 Fixed Experiment Runner (WORKING VERSION)\n",
    "\n",
    "This cell contains the corrected approach to run experiments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54335,
     "status": "aborted",
     "timestamp": 1750704728390,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "FVc8X8w2HkM2"
   },
   "outputs": [],
   "source": [
    "# 🔧 CORRECTED APPROACH: Run experiments directly with fixed tuner\n",
    "print(\"🚀 Starting experiments with CORRECTED FixedHyperparameterTuner...\")\n",
    "\n",
    "# Initialize the fixed tuner\n",
    "fixed_tuner = FixedHyperparameterTuner()\n",
    "\n",
    "# Define experiment configurations directly (not using the config file)\n",
    "experiments = {\n",
    "    'baseline_gpu_optimized_fixed': {\n",
    "        'experiment_name': 'baseline_gpu_optimized_fixed',\n",
    "        'model': {\n",
    "            'name': 'medium',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 128,\n",
    "            'learning_rate': 0.002,\n",
    "            'weight_decay': 0.0001,\n",
    "            'num_epochs': 25,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.1\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adamw',\n",
    "            'betas': [0.9, 0.999]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'cosine',\n",
    "            'warmup_epochs': 3,\n",
    "            'min_lr': 1e-6\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'aggressive_learning_fixed': {\n",
    "        'experiment_name': 'aggressive_learning_fixed',\n",
    "        'model': {\n",
    "            'name': 'medium',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 256,\n",
    "            'learning_rate': 0.003,\n",
    "            'weight_decay': 0.00005,\n",
    "            'num_epochs': 25,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.05\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adam',\n",
    "            'betas': [0.9, 0.999]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'step',\n",
    "            'step_size': 8,\n",
    "            'gamma': 0.5\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'large_model_gpu_fixed': {\n",
    "        'experiment_name': 'large_model_gpu_fixed',\n",
    "        'model': {\n",
    "            'name': 'large',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 64,\n",
    "            'learning_rate': 0.0008,\n",
    "            'weight_decay': 0.0003,\n",
    "            'num_epochs': 30,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.15\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adamw',\n",
    "            'betas': [0.9, 0.99]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'cosine',\n",
    "            'warmup_epochs': 5,\n",
    "            'min_lr': 1e-7\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"📋 Will run {len(experiments)} experiments:\")\n",
    "for name in experiments.keys():\n",
    "    print(f\"  • {name}\")\n",
    "print()\n",
    "\n",
    "# Run experiments one by one and collect results\n",
    "results = []\n",
    "for exp_name, exp_config in experiments.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🧪 Starting experiment: {exp_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    result = fixed_tuner.run_single_experiment(exp_name, exp_config)\n",
    "    results.append(result)\n",
    "\n",
    "    # Print immediate result\n",
    "    if result['status'] == 'completed':\n",
    "        print(f\"✅ {exp_name} completed!\")\n",
    "        print(f\"   Character accuracy: {result['best_val_char_accuracy']:.4f}\")\n",
    "        print(f\"   Sequence accuracy: {result['best_val_seq_accuracy']:.4f}\")\n",
    "        print(f\"   Training time: {result['training_time']/60:.1f} minutes\")\n",
    "    else:\n",
    "        print(f\"❌ {exp_name} failed: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "    # Clear memory after each experiment\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n🎉 All experiments completed!\")\n",
    "print(f\"📊 Results summary:\")\n",
    "print(f\"  • Total experiments: {len(results)}\")\n",
    "print(f\"  • Successful: {sum(1 for r in results if r['status'] == 'completed')}\")\n",
    "print(f\"  • Failed: {sum(1 for r in results if r['status'] == 'failed')}\")\n",
    "\n",
    "# Find best result\n",
    "best_result = None\n",
    "for result in results:\n",
    "    if result['status'] == 'completed':\n",
    "        if best_result is None or result['best_val_char_accuracy'] > best_result['best_val_char_accuracy']:\n",
    "            best_result = result\n",
    "\n",
    "if best_result:\n",
    "    print(f\"\\n🏆 Best experiment: {best_result['experiment_name']}\")\n",
    "    print(f\"  • Character accuracy: {best_result['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"  • Sequence accuracy: {best_result['best_val_seq_accuracy']:.4f}\")\n",
    "    print(f\"  • Training time: {best_result['training_time']/60:.1f} minutes\")\n",
    "    print(f\"  • Epochs completed: {best_result['epochs_trained']}\")\n",
    "else:\n",
    "    print(\"\\n❌ No successful experiments\")\n",
    "\n",
    "# Save results to Google Drive\n",
    "print(f\"\\n💾 Saving results to Google Drive...\")\n",
    "tuner.results = results  # Update the tuner's results\n",
    "if best_result:\n",
    "    tuner.best_result = best_result\n",
    "results_file = tuner.save_results()\n",
    "print(f\"✅ Results saved to: {results_file}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "uQgtR8ZbHkNB",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🛠️ Standalone Fixed Hyperparameter Tuner\n",
    "\n",
    "Let's create a standalone version that doesn't require external config files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54333,
     "status": "aborted",
     "timestamp": 1750704728392,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "24lYESyJHkNB"
   },
   "outputs": [],
   "source": [
    "# 🛠️ STANDALONE FIXED HYPERPARAMETER TUNER (No external configs needed!)\n",
    "print(\"🚀 Creating standalone hyperparameter tuning system...\")\n",
    "\n",
    "class StandaloneHyperparameterTuner:\n",
    "    \"\"\"Standalone hyperparameter tuner that doesn't require external config files.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the standalone tuner.\"\"\"\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.results = []\n",
    "        self.best_result = None\n",
    "\n",
    "        # Load metadata\n",
    "        with open('generated_data/metadata.yaml', 'r') as f:\n",
    "            self.metadata = yaml.safe_load(f)\n",
    "\n",
    "        print(f\"🔥 Using device: {self.device}\")\n",
    "        print(f\"📊 Dataset loaded with {self.metadata['dataset_info']['total_samples']} samples\")\n",
    "\n",
    "    def run_single_experiment(self, experiment_name, experiment_config):\n",
    "        \"\"\"Run a single hyperparameter experiment.\"\"\"\n",
    "        print(f\"🧪 Starting experiment: {experiment_name}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Create datasets\n",
    "            train_data = KhmerDataset(\n",
    "                self.metadata['splits']['train'],\n",
    "                self.metadata['dataset_info']['char_to_idx'],\n",
    "                self.metadata['dataset_info']['max_sequence_length'] + 1\n",
    "            )\n",
    "\n",
    "            val_data = KhmerDataset(\n",
    "                self.metadata['splits']['val'],\n",
    "                self.metadata['dataset_info']['char_to_idx'],\n",
    "                self.metadata['dataset_info']['max_sequence_length'] + 1\n",
    "            )\n",
    "\n",
    "            # Create data loaders with adaptive batch size\n",
    "            batch_size = experiment_config['training']['batch_size']\n",
    "            if self.device.type == 'cpu':\n",
    "                batch_size = min(32, batch_size)  # Smaller batch for CPU\n",
    "                print(f\"⚠️ Using smaller batch size ({batch_size}) for CPU training\")\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                train_data,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                pin_memory=(self.device.type == 'cuda')\n",
    "            )\n",
    "\n",
    "            val_loader = DataLoader(\n",
    "                val_data,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                pin_memory=(self.device.type == 'cuda')\n",
    "            )\n",
    "\n",
    "            print(f\"📈 Training samples: {len(train_data)}\")\n",
    "            print(f\"📊 Validation samples: {len(val_data)}\")\n",
    "            print(f\"🔢 Batch size: {batch_size}\")\n",
    "\n",
    "            # Create fixed model\n",
    "            model = create_model_fixed(\n",
    "                model_size=experiment_config['model']['name'],\n",
    "                vocab_size=len(self.metadata['dataset_info']['char_to_idx']),\n",
    "                max_sequence_length=self.metadata['dataset_info']['max_sequence_length'] + 1\n",
    "            )\n",
    "\n",
    "            print(f\"🧠 Model created: {experiment_config['model']['name']}\")\n",
    "            print(f\"📏 Max sequence length: {model.max_sequence_length}\")\n",
    "\n",
    "            # Create trainer\n",
    "            trainer = FixedSimpleTrainer(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                config=experiment_config,\n",
    "                device=self.device,\n",
    "                char_to_idx=self.metadata['dataset_info']['char_to_idx']\n",
    "            )\n",
    "\n",
    "            # Run training\n",
    "            print(f\"🚀 Starting training for {experiment_config['training']['num_epochs']} epochs...\")\n",
    "            history = trainer.train()\n",
    "\n",
    "            # Calculate metrics\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            # Create result\n",
    "            result = {\n",
    "                'experiment_name': experiment_name,\n",
    "                'status': 'completed',\n",
    "                'training_time': training_time,\n",
    "                'best_val_char_accuracy': max(history['val_char_accuracy']) if history['val_char_accuracy'] else 0,\n",
    "                'best_val_seq_accuracy': max(history['val_seq_accuracy']) if history['val_seq_accuracy'] else 0,\n",
    "                'final_train_loss': history['train_loss'][-1] if history['train_loss'] else float('inf'),\n",
    "                'final_val_loss': history['val_loss'][-1] if history['val_loss'] else float('inf'),\n",
    "                'epochs_trained': len(history['train_loss']),\n",
    "                'hyperparameters': {\n",
    "                    'model_size': experiment_config['model']['name'],\n",
    "                    'batch_size': batch_size,\n",
    "                    'learning_rate': experiment_config['training']['learning_rate'],\n",
    "                    'weight_decay': experiment_config['training']['weight_decay'],\n",
    "                    'optimizer': experiment_config['optimizer']['type'],\n",
    "                    'scheduler': experiment_config['scheduler']['type']\n",
    "                },\n",
    "                'history': self.convert_tensors_to_python(history)\n",
    "            }\n",
    "\n",
    "            # Save model to Google Drive if best model exists\n",
    "            if trainer.best_model_state:\n",
    "                model_filename = f\"{experiment_name}_best_model.pth\"\n",
    "                model_path = f\"{project_drive_path}/models/{model_filename}\"\n",
    "                torch.save({\n",
    "                    'model_state_dict': trainer.best_model_state,\n",
    "                    'config': experiment_config,\n",
    "                    'metadata': self.metadata,\n",
    "                    'result': result\n",
    "                }, model_path)\n",
    "                result['model_path'] = model_path\n",
    "                print(f\"💾 Model saved to: {model_path}\")\n",
    "\n",
    "            print(f\"✅ Experiment {experiment_name} completed successfully!\")\n",
    "            print(f\"📊 Best character accuracy: {result['best_val_char_accuracy']:.4f}\")\n",
    "            print(f\"📊 Best sequence accuracy: {result['best_val_seq_accuracy']:.4f}\")\n",
    "            print(f\"⏱️ Training time: {training_time/60:.1f} minutes\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Experiment {experiment_name} failed: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {\n",
    "                'experiment_name': experiment_name,\n",
    "                'status': 'failed',\n",
    "                'error': str(e),\n",
    "                'training_time': time.time() - start_time\n",
    "            }\n",
    "\n",
    "    def convert_tensors_to_python(self, obj):\n",
    "        \"\"\"Recursively convert tensors to Python types for JSON serialization.\"\"\"\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.item() if obj.numel() == 1 else obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: self.convert_tensors_to_python(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self.convert_tensors_to_python(item) for item in obj]\n",
    "        elif isinstance(obj, (int, float, str, bool, type(None))):\n",
    "            return obj\n",
    "        else:\n",
    "            return str(obj)\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"Save tuning results to Google Drive.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Convert tensors to Python types for JSON serialization\n",
    "        serializable_results = self.convert_tensors_to_python({\n",
    "            'timestamp': timestamp,\n",
    "            'device': str(self.device),\n",
    "            'dataset_info': self.metadata['dataset_info'],\n",
    "            'best_result': self.best_result,\n",
    "            'all_results': self.results,\n",
    "            'summary': self.generate_summary()\n",
    "        })\n",
    "\n",
    "        # Save detailed results\n",
    "        results_file = f\"{project_drive_path}/results/hyperparameter_tuning_results_{timestamp}.json\"\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "\n",
    "        print(f\"💾 Results saved to: {results_file}\")\n",
    "        return results_file\n",
    "\n",
    "    def generate_summary(self):\n",
    "        \"\"\"Generate experiment summary.\"\"\"\n",
    "        if not self.results:\n",
    "            return {}\n",
    "\n",
    "        completed_results = [r for r in self.results if r.get('status') == 'completed']\n",
    "\n",
    "        if not completed_results:\n",
    "            return {'message': 'No completed experiments'}\n",
    "\n",
    "        return {\n",
    "            'total_experiments': len(self.results),\n",
    "            'completed_experiments': len(completed_results),\n",
    "            'failed_experiments': len(self.results) - len(completed_results),\n",
    "            'best_char_accuracy': max(r['best_val_char_accuracy'] for r in completed_results),\n",
    "            'best_seq_accuracy': max(r['best_val_seq_accuracy'] for r in completed_results),\n",
    "            'average_training_time': sum(r['training_time'] for r in completed_results) / len(completed_results),\n",
    "            'best_experiment': self.best_result['experiment_name'] if self.best_result else None\n",
    "        }\n",
    "\n",
    "print(\"✅ Standalone hyperparameter tuning system created!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "84kx1B2kHkNB",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🎯 Run Experiments with Standalone Tuner\n",
    "\n",
    "Now let's run all experiments with the standalone system:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54332,
     "status": "aborted",
     "timestamp": 1750704728394,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "WAdnsI67HkNB"
   },
   "outputs": [],
   "source": [
    "# 🎯 RUN ALL EXPERIMENTS WITH STANDALONE TUNER\n",
    "print(\"🚀 Starting all experiments with standalone tuner...\")\n",
    "\n",
    "# Initialize the standalone tuner (no config files needed!)\n",
    "tuner = StandaloneHyperparameterTuner()\n",
    "\n",
    "# Define experiment configurations with early_stopping configuration\n",
    "experiments = {\n",
    "    'baseline_gpu_optimized_fixed': {\n",
    "        'experiment_name': 'baseline_gpu_optimized_fixed',\n",
    "        'model': {\n",
    "            'name': 'medium',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 128,\n",
    "            'learning_rate': 0.002,\n",
    "            'weight_decay': 0.0001,\n",
    "            'num_epochs': 25,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.1\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adamw',\n",
    "            'betas': [0.9, 0.999]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'cosine',\n",
    "            'warmup_epochs': 3,\n",
    "            'min_lr': 1e-6\n",
    "        },\n",
    "        'early_stopping': {\n",
    "            'patience': 5,\n",
    "            'min_delta': 0.001,\n",
    "            'monitor': 'val_char_accuracy'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'aggressive_learning_fixed': {\n",
    "        'experiment_name': 'aggressive_learning_fixed',\n",
    "        'model': {\n",
    "            'name': 'medium',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 256,\n",
    "            'learning_rate': 0.003,\n",
    "            'weight_decay': 0.00005,\n",
    "            'num_epochs': 25,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.05\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adam',\n",
    "            'betas': [0.9, 0.999]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'step',\n",
    "            'step_size': 8,\n",
    "            'gamma': 0.5\n",
    "        },\n",
    "        'early_stopping': {\n",
    "            'patience': 5,\n",
    "            'min_delta': 0.001,\n",
    "            'monitor': 'val_char_accuracy'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'large_model_gpu_fixed': {\n",
    "        'experiment_name': 'large_model_gpu_fixed',\n",
    "        'model': {\n",
    "            'name': 'large',\n",
    "            'config_path': 'config/model_config.yaml'\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 64,\n",
    "            'learning_rate': 0.0008,\n",
    "            'weight_decay': 0.0003,\n",
    "            'num_epochs': 30,\n",
    "            'loss_type': 'crossentropy',\n",
    "            'label_smoothing': 0.15\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'type': 'adamw',\n",
    "            'betas': [0.9, 0.99]\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'cosine',\n",
    "            'warmup_epochs': 5,\n",
    "            'min_lr': 1e-7\n",
    "        },\n",
    "        'early_stopping': {\n",
    "            'patience': 7,\n",
    "            'min_delta': 0.001,\n",
    "            'monitor': 'val_char_accuracy'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"📋 Will run {len(experiments)} experiments:\")\n",
    "for name in experiments.keys():\n",
    "    print(f\"  • {name}\")\n",
    "print()\n",
    "\n",
    "# Run experiments one by one\n",
    "results = []\n",
    "for exp_name, exp_config in experiments.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🧪 Starting experiment: {exp_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    result = tuner.run_single_experiment(exp_name, exp_config)\n",
    "    results.append(result)\n",
    "    tuner.results.append(result)  # Add to tuner's results too\n",
    "\n",
    "    # Update best result\n",
    "    if (result.get('status') == 'completed' and\n",
    "        (tuner.best_result is None or\n",
    "         result['best_val_char_accuracy'] > tuner.best_result['best_val_char_accuracy'])):\n",
    "        tuner.best_result = result\n",
    "\n",
    "    # Print immediate result\n",
    "    if result['status'] == 'completed':\n",
    "        print(f\"✅ {exp_name} completed!\")\n",
    "        print(f\"   Character accuracy: {result['best_val_char_accuracy']:.4f}\")\n",
    "        print(f\"   Sequence accuracy: {result['best_val_seq_accuracy']:.4f}\")\n",
    "        print(f\"   Training time: {result['training_time']/60:.1f} minutes\")\n",
    "    else:\n",
    "        print(f\"❌ {exp_name} failed: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "    # Clear memory after each experiment\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n🎉 All experiments completed!\")\n",
    "print(f\"📊 Results summary:\")\n",
    "print(f\"  • Total experiments: {len(results)}\")\n",
    "print(f\"  • Successful: {sum(1 for r in results if r['status'] == 'completed')}\")\n",
    "print(f\"  • Failed: {sum(1 for r in results if r['status'] == 'failed')}\")\n",
    "\n",
    "# Find best result\n",
    "if tuner.best_result:\n",
    "    print(f\"\\n🏆 Best experiment: {tuner.best_result['experiment_name']}\")\n",
    "    print(f\"  • Character accuracy: {tuner.best_result['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"  • Sequence accuracy: {tuner.best_result['best_val_seq_accuracy']:.4f}\")\n",
    "    print(f\"  • Training time: {tuner.best_result['training_time']/60:.1f} minutes\")\n",
    "    print(f\"  • Epochs completed: {tuner.best_result['epochs_trained']}\")\n",
    "else:\n",
    "    print(\"\\n❌ No successful experiments\")\n",
    "\n",
    "# Save results to Google Drive\n",
    "print(f\"\\n💾 Saving results to Google Drive...\")\n",
    "results_file = tuner.save_results()\n",
    "print(f\"✅ Results saved to: {results_file}\")\n",
    "\n",
    "# Display summary\n",
    "summary = tuner.generate_summary()\n",
    "print(f\"\\n📈 FINAL SUMMARY:\")\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  • {key}: {value:.4f}\")\n",
    "    elif key.endswith('_time'):\n",
    "        print(f\"  • {key}: {value/60:.1f} minutes\" if isinstance(value, (int, float)) else f\"  • {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  • {key}: {value}\")\n",
    "\n",
    "print(f\"\\n🎊 Hyperparameter tuning completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "VZBpQkX-HkNC",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ⚠️ IMPORTANT: Use the Correct Cells!\n",
    "\n",
    "**🚨 TO AVOID SEQUENCE LENGTH ERRORS:**\n",
    "\n",
    "✅ **CORRECT CELLS TO RUN:**\n",
    "- **Cell 40**: `🛠️ STANDALONE FIXED HYPERPARAMETER TUNER`\n",
    "- **Cell 42**: `🎯 RUN ALL EXPERIMENTS WITH STANDALONE TUNER`\n",
    "\n",
    "❌ **DO NOT RUN THESE OLD CELLS (they have bugs):**\n",
    "- Cell 27: Old hyperparameter tuner (has sequence length issues)\n",
    "- Cell 28: Old results saving\n",
    "- Cell 36: Old experiment runner (returns None)\n",
    "- Cell 38: Old fixed experiment runner (config file issues)\n",
    "\n",
    "**🎯 The standalone tuner (cells 40 + 42) fixes all issues:**\n",
    "- ✅ No config file dependencies\n",
    "- ✅ Fixed sequence length matching\n",
    "- ✅ Proper results collection\n",
    "- ✅ Google Drive integration\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "6-R8gaBkHkNC",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🔧 Quick Test: Run Single Experiment\n",
    "\n",
    "Let's test one experiment first to make sure everything works:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54332,
     "status": "aborted",
     "timestamp": 1750704728397,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "NY6iq8WCHkNC"
   },
   "outputs": [],
   "source": [
    "# 🔧 QUICK TEST: Run one experiment with FIXED configuration\n",
    "print(\"🧪 Testing one experiment with fixed early_stopping configuration...\")\n",
    "\n",
    "# Initialize the standalone tuner\n",
    "test_tuner = StandaloneHyperparameterTuner()\n",
    "\n",
    "# Test configuration with early_stopping included\n",
    "test_config = {\n",
    "    'experiment_name': 'test_fixed_config',\n",
    "    'model': {\n",
    "        'name': 'small',  # Use small model for faster testing\n",
    "        'config_path': 'config/model_config.yaml'\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 32,  # Small batch for quick test\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 0.0001,\n",
    "        'num_epochs': 5,  # Only 5 epochs for quick test\n",
    "        'loss_type': 'crossentropy',\n",
    "        'label_smoothing': 0.1\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'type': 'adamw',\n",
    "        'betas': [0.9, 0.999]\n",
    "    },\n",
    "    'scheduler': {\n",
    "        'type': 'cosine',\n",
    "        'warmup_epochs': 1,\n",
    "        'min_lr': 1e-6\n",
    "    },\n",
    "    'early_stopping': {\n",
    "        'patience': 3,\n",
    "        'min_delta': 0.001,\n",
    "        'monitor': 'val_char_accuracy'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"📋 Test configuration:\")\n",
    "print(f\"  • Model: {test_config['model']['name']}\")\n",
    "print(f\"  • Batch size: {test_config['training']['batch_size']}\")\n",
    "print(f\"  • Epochs: {test_config['training']['num_epochs']}\")\n",
    "print(f\"  • Early stopping patience: {test_config['early_stopping']['patience']}\")\n",
    "\n",
    "# Run the test experiment\n",
    "result = test_tuner.run_single_experiment('test_fixed_config', test_config)\n",
    "\n",
    "print(f\"\\n📊 Test result:\")\n",
    "print(f\"  • Status: {result['status']}\")\n",
    "if result['status'] == 'completed':\n",
    "    print(f\"  • Character accuracy: {result['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"  • Sequence accuracy: {result['best_val_seq_accuracy']:.4f}\")\n",
    "    print(f\"  • Training time: {result['training_time']:.1f} seconds\")\n",
    "    print(f\"  • Epochs completed: {result['epochs_trained']}\")\n",
    "    print(\"  ✅ SUCCESS! Configuration is working correctly!\")\n",
    "else:\n",
    "    print(f\"  • Error: {result.get('error', 'Unknown error')}\")\n",
    "    print(\"  ❌ There's still an issue with the configuration\")\n",
    "\n",
    "# Clear memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if result['status'] == 'completed':\n",
    "    print(\"🎉 TEST PASSED! Configuration is working correctly.\")\n",
    "    print(\"💡 You can now run the full experiments in cell 42.\")\n",
    "else:\n",
    "    print(\"❌ Test failed. Please check the error above.\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "wvnTD0CvHkNC",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ⚠️ CELLS REMOVED TO PREVENT CONFUSION\n",
    "\n",
    "**The following old cells have been removed/disabled:**\n",
    "\n",
    "❌ **Cell 26**: Old FixedHyperparameterTuner (config file issues)\n",
    "❌ **Cell 27**: Old experiment runner (sequence length errors)\n",
    "❌ **Cell 48-55**: Old hyperparameter tuning system (broken)\n",
    "\n",
    "✅ **USE THESE WORKING CELLS INSTEAD:**\n",
    "- **Cell 40**: `StandaloneHyperparameterTuner` (working version)\n",
    "- **Cell 42**: `🎯 RUN ALL EXPERIMENTS` (working version)\n",
    "- **Cell 45**: Quick test (verification)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "XoNr6WirHkNC",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ✅ CORRECT CELLS TO RUN FOR HYPERPARAMETER TUNING\n",
    "\n",
    "**🎯 FOR SUCCESSFUL HYPERPARAMETER TUNING, RUN THESE CELLS IN ORDER:**\n",
    "\n",
    "1. **Cell 40**: `🛠️ STANDALONE FIXED HYPERPARAMETER TUNER`\n",
    "   - Creates the working `StandaloneHyperparameterTuner` class\n",
    "   - No config file dependencies\n",
    "   - Fixed sequence length issues\n",
    "\n",
    "2. **Cell 45**: `🔧 Quick Test` (Optional but recommended)\n",
    "   - Tests the system with a small experiment\n",
    "   - Verifies everything works before full run\n",
    "\n",
    "3. **Cell 42**: `🎯 RUN ALL EXPERIMENTS WITH STANDALONE TUNER`\n",
    "   - Runs all 3 hyperparameter experiments\n",
    "   - Saves results to Google Drive\n",
    "   - Shows final summary\n",
    "\n",
    "**❌ DO NOT RUN THESE DISABLED CELLS:**\n",
    "- Cell 26, 27: Old broken systems\n",
    "- Cells 49-56: Old hyperparameter tuning section\n",
    "- Cell 34: References old broken class\n",
    "\n",
    "**🚀 Ready to run? Start with Cell 40!**\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "z8NN2BKyHkND",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Hyperparameter Tuning System with Google Drive Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54331,
     "status": "aborted",
     "timestamp": 1750704728399,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "3_MrXNiWHkND"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning System\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    \"\"\"Comprehensive hyperparameter tuning system for Colab.\"\"\"\n",
    "\n",
    "    def __init__(self, config_file='config/phase3_colab_configs.yaml'):\n",
    "        self.config_file = config_file\n",
    "        self.results = []\n",
    "        self.best_result = None\n",
    "        self.experiments_completed = 0\n",
    "\n",
    "        # Load configuration\n",
    "        with open(config_file, 'r') as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "\n",
    "        # Load metadata\n",
    "        with open('generated_data/metadata.yaml', 'r') as f:\n",
    "            self.metadata = yaml.safe_load(f)\n",
    "\n",
    "        # Device setup\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"🔥 Using device: {self.device}\")\n",
    "\n",
    "    def create_data_loaders(self, batch_size):\n",
    "        \"\"\"Create train and validation data loaders.\"\"\"\n",
    "        train_dataset = KhmerDataset(\n",
    "            self.metadata['splits']['train'],\n",
    "            self.metadata['dataset_info']['char_to_idx'],\n",
    "            self.metadata['dataset_info']['max_sequence_length'] + 1\n",
    "        )\n",
    "\n",
    "        val_dataset = KhmerDataset(\n",
    "            self.metadata['splits']['val'],\n",
    "            self.metadata['dataset_info']['char_to_idx'],\n",
    "            self.metadata['dataset_info']['max_sequence_length'] + 1\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True if self.device.type == 'cuda' else False\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True if self.device.type == 'cuda' else False\n",
    "        )\n",
    "\n",
    "        return train_loader, val_loader\n",
    "\n",
    "    def run_single_experiment(self, experiment_name, experiment_config):\n",
    "        \"\"\"Run a single hyperparameter experiment.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"🧪 Starting experiment: {experiment_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Merge base config with experiment config\n",
    "            merged_config = copy.deepcopy(self.config['base_config'])\n",
    "            merged_config.update(experiment_config)\n",
    "\n",
    "            # Create data loaders\n",
    "            train_loader, val_loader = self.create_data_loaders(\n",
    "                merged_config['training']['batch_size']\n",
    "            )\n",
    "\n",
    "            # Create model\n",
    "            model = create_model(\n",
    "                model_size=merged_config['model']['name'],\n",
    "                vocab_size=len(self.metadata['dataset_info']['char_to_idx']),\n",
    "                max_sequence_length=self.metadata['dataset_info']['max_sequence_length'] + 1\n",
    "            )\n",
    "\n",
    "            # Initialize trainer\n",
    "            trainer = SimpleTrainer(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                config=merged_config,\n",
    "                device=self.device\n",
    "            )\n",
    "\n",
    "            # Run training\n",
    "            history = trainer.train()\n",
    "\n",
    "            # Calculate metrics\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            # Create result\n",
    "            result = {\n",
    "                'experiment_name': experiment_name,\n",
    "                'status': 'completed',\n",
    "                'training_time': training_time,\n",
    "                'best_val_char_accuracy': max(history['val_char_accuracy']),\n",
    "                'best_val_seq_accuracy': max(history['val_seq_accuracy']),\n",
    "                'final_train_loss': history['train_loss'][-1],\n",
    "                'final_val_loss': history['val_loss'][-1],\n",
    "                'epochs_trained': len(history['train_loss']),\n",
    "                'hyperparameters': {\n",
    "                    'model_size': merged_config['model']['name'],\n",
    "                    'batch_size': merged_config['training']['batch_size'],\n",
    "                    'learning_rate': merged_config['training']['learning_rate'],\n",
    "                    'weight_decay': merged_config['training']['weight_decay'],\n",
    "                    'optimizer': merged_config['optimizer']['type'],\n",
    "                    'scheduler': merged_config['scheduler']['type']\n",
    "                },\n",
    "                'history': history\n",
    "            }\n",
    "\n",
    "            # Save model to Google Drive\n",
    "            if trainer.best_model_state:\n",
    "                model_filename = f\"{experiment_name}_best_model.pth\"\n",
    "                model_path = f\"{project_drive_path}/models/{model_filename}\"\n",
    "                torch.save({\n",
    "                    'model_state_dict': trainer.best_model_state,\n",
    "                    'config': merged_config,\n",
    "                    'metadata': self.metadata,\n",
    "                    'result': result\n",
    "                }, model_path)\n",
    "                result['model_path'] = model_path\n",
    "                print(f\"💾 Model saved to: {model_path}\")\n",
    "\n",
    "            print(f\"✅ Experiment {experiment_name} completed successfully!\")\n",
    "            print(f\"📊 Best character accuracy: {result['best_val_char_accuracy']:.4f}\")\n",
    "            print(f\"📊 Best sequence accuracy: {result['best_val_seq_accuracy']:.4f}\")\n",
    "            print(f\"⏱️ Training time: {training_time/60:.1f} minutes\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Experiment {experiment_name} failed: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {\n",
    "                'experiment_name': experiment_name,\n",
    "                'status': 'failed',\n",
    "                'error': str(e),\n",
    "                'training_time': time.time() - start_time\n",
    "            }\n",
    "\n",
    "    def run_experiments(self, experiment_names=None):\n",
    "        \"\"\"Run all or specified experiments.\"\"\"\n",
    "        experiments = self.config['experiments']\n",
    "\n",
    "        if experiment_names:\n",
    "            experiments = {name: config for name, config in experiments.items()\n",
    "                          if name in experiment_names}\n",
    "\n",
    "        print(f\"🎯 Starting hyperparameter tuning with {len(experiments)} experiments\")\n",
    "        print(f\"📊 Total dataset size: {self.metadata['dataset_info']['total_samples']}\")\n",
    "        print(f\"🏋️ Training samples: {self.metadata['dataset_info']['train_samples']}\")\n",
    "        print(f\"🔬 Validation samples: {self.metadata['dataset_info']['val_samples']}\")\n",
    "\n",
    "        for exp_name, exp_config in experiments.items():\n",
    "            result = self.run_single_experiment(exp_name, exp_config)\n",
    "            self.results.append(result)\n",
    "\n",
    "            # Update best result\n",
    "            if (result.get('status') == 'completed' and\n",
    "                (self.best_result is None or\n",
    "                 result['best_val_char_accuracy'] >\n",
    "                 self.best_result['best_val_char_accuracy'])):\n",
    "                self.best_result = result\n",
    "\n",
    "            self.experiments_completed += 1\n",
    "\n",
    "            # Clear memory\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"Save tuning results to Google Drive.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Save detailed results\n",
    "        results_file = f\"{project_drive_path}/results/hyperparameter_tuning_results_{timestamp}.json\"\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump({\n",
    "                'timestamp': timestamp,\n",
    "                'device': str(self.device),\n",
    "                'dataset_info': self.metadata['dataset_info'],\n",
    "                'best_result': self.best_result,\n",
    "                'all_results': self.results,\n",
    "                'summary': self.generate_summary()\n",
    "            }, f, indent=2)\n",
    "\n",
    "        # Save summary CSV\n",
    "        summary_file = f\"{project_drive_path}/results/summary_{timestamp}.csv\"\n",
    "        self.save_summary_csv(summary_file)\n",
    "\n",
    "        print(f\"💾 Results saved to: {results_file}\")\n",
    "        print(f\"📊 Summary saved to: {summary_file}\")\n",
    "\n",
    "        return results_file, summary_file\n",
    "\n",
    "    def generate_summary(self):\n",
    "        \"\"\"Generate experiment summary.\"\"\"\n",
    "        if not self.results:\n",
    "            return {}\n",
    "\n",
    "        completed_results = [r for r in self.results if r.get('status') == 'completed']\n",
    "\n",
    "        if not completed_results:\n",
    "            return {'message': 'No completed experiments'}\n",
    "\n",
    "        return {\n",
    "            'total_experiments': len(self.results),\n",
    "            'completed_experiments': len(completed_results),\n",
    "            'failed_experiments': len(self.results) - len(completed_results),\n",
    "            'best_char_accuracy': max(r['best_val_char_accuracy'] for r in completed_results),\n",
    "            'best_seq_accuracy': max(r['best_val_seq_accuracy'] for r in completed_results),\n",
    "            'average_training_time': sum(r['training_time'] for r in completed_results) / len(completed_results),\n",
    "            'best_experiment': self.best_result['experiment_name'] if self.best_result else None\n",
    "        }\n",
    "\n",
    "    def save_summary_csv(self, filename):\n",
    "        \"\"\"Save summary as CSV.\"\"\"\n",
    "        import pandas as pd\n",
    "\n",
    "        data = []\n",
    "        for result in self.results:\n",
    "            if result.get('status') == 'completed':\n",
    "                data.append({\n",
    "                    'experiment_name': result['experiment_name'],\n",
    "                    'char_accuracy': result['best_val_char_accuracy'],\n",
    "                    'seq_accuracy': result['best_val_seq_accuracy'],\n",
    "                    'training_time_min': result['training_time'] / 60,\n",
    "                    'epochs_trained': result['epochs_trained'],\n",
    "                    **result['hyperparameters']\n",
    "                })\n",
    "\n",
    "        if data:\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(filename, index=False)\n",
    "\n",
    "    def plot_results(self):\n",
    "        \"\"\"Plot experiment results.\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to plot\")\n",
    "            return\n",
    "\n",
    "        completed_results = [r for r in self.results if r.get('status') == 'completed']\n",
    "\n",
    "        if not completed_results:\n",
    "            print(\"No completed experiments to plot\")\n",
    "            return\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "        # Character accuracy\n",
    "        exp_names = [r['experiment_name'] for r in completed_results]\n",
    "        char_accs = [r['best_val_char_accuracy'] for r in completed_results]\n",
    "\n",
    "        axes[0, 0].bar(exp_names, char_accs)\n",
    "        axes[0, 0].set_title('Best Character Accuracy by Experiment')\n",
    "        axes[0, 0].set_ylabel('Character Accuracy')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Sequence accuracy\n",
    "        seq_accs = [r['best_val_seq_accuracy'] for r in completed_results]\n",
    "        axes[0, 1].bar(exp_names, seq_accs)\n",
    "        axes[0, 1].set_title('Best Sequence Accuracy by Experiment')\n",
    "        axes[0, 1].set_ylabel('Sequence Accuracy')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Training time\n",
    "        training_times = [r['training_time'] / 60 for r in completed_results]\n",
    "        axes[1, 0].bar(exp_names, training_times)\n",
    "        axes[1, 0].set_title('Training Time by Experiment')\n",
    "        axes[1, 0].set_ylabel('Training Time (minutes)')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Learning curves for best experiment\n",
    "        if self.best_result:\n",
    "            history = self.best_result['history']\n",
    "            epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "            axes[1, 1].plot(epochs, history['train_loss'], label='Train Loss')\n",
    "            axes[1, 1].plot(epochs, history['val_loss'], label='Val Loss')\n",
    "            axes[1, 1].plot(epochs, history['val_char_accuracy'], label='Val Char Acc')\n",
    "            axes[1, 1].set_title(f\"Learning Curves - {self.best_result['experiment_name']}\")\n",
    "            axes[1, 1].set_xlabel('Epoch')\n",
    "            axes[1, 1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{project_drive_path}/results/experiment_plots_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "        plt.show()\n",
    "\n",
    "print(\"✅ Hyperparameter tuning system created!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Hq1g-vqeHkND",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ❌ 9. DISABLED - Old Hyperparameter Tuning (DO NOT USE)\n",
    "\n",
    "**⚠️ THIS SECTION IS DISABLED**\n",
    "\n",
    "This old section has sequence length errors and config file issues.\n",
    "\n",
    "**✅ USE THE NEW WORKING SYSTEM INSTEAD:**\n",
    "- **Cell 40**: StandaloneHyperparameterTuner\n",
    "- **Cell 42**: Run All Experiments\n",
    "- **Cell 45**: Quick Test\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "57hCcUhnHkNE",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 10. Results Analysis & Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54370,
     "status": "aborted",
     "timestamp": 1750704728449,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "0gGMgOrzHkNE"
   },
   "outputs": [],
   "source": [
    "# ⚠️ CELL DISABLED - References old tuner system\n",
    "print(\"❌ This cell is DISABLED!\")\n",
    "print(\"✅ Results are automatically saved by the StandaloneHyperparameterTuner!\")\n",
    "print(\"💾 Check Google Drive for saved results and models\")\n",
    "print(\"📁 Location: /content/drive/MyDrive/khmer_ocr_training/\")\n",
    "\n",
    "# OLD CODE DISABLED - references old broken tuner system\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Khmer OCR Hyperparameter Tuning on Google Colab\n",
    "\n",
    "This notebook performs systematic hyperparameter tuning for Khmer digits OCR model optimization.\n",
    "\n",
    "**Features:**\n",
    "- Complete setup from scratch on Google Colab\n",
    "- GPU acceleration support\n",
    "- Automatic data generation\n",
    "- Multiple hyperparameter experiments\n",
    "- Google Drive integration for model storage\n",
    "- Real-time training monitoring\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "gKOFp3sCHkNE",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 11. Model Loading & Testing (Optional)\n",
    "\n",
    "If you want to load and test the best model later, use the code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54369,
     "status": "aborted",
     "timestamp": 1750704728450,
     "user": {
      "displayName": "Sokunthet Sok",
      "userId": "01123156325231328650"
     },
     "user_tz": -420
    },
    "id": "g4xTGba1HkNE"
   },
   "outputs": [],
   "source": [
    "# ⚠️ CELL DISABLED - References old tuner system\n",
    "print(\"❌ This cell is DISABLED!\")\n",
    "print(\"✅ Best models are automatically saved to Google Drive!\")\n",
    "print(\"📁 Check: /content/drive/MyDrive/khmer_ocr_training/models/\")\n",
    "print(\"💡 Download the best model and load it in a new notebook for testing\")\n",
    "\n",
    "# OLD CODE DISABLED - references old broken tuner system\n",
    "if False:  # Disabled\n",
    "    print(\"🔄 Loading best model for testing...\")\n",
    "\n",
    "    # Load saved model\n",
    "    checkpoint = torch.load(tuner.best_result['model_path'], map_location=tuner.device)\n",
    "\n",
    "    # Create model\n",
    "    best_model = create_model(\n",
    "        model_size=checkpoint['config']['model']['name'],\n",
    "        vocab_size=len(checkpoint['metadata']['dataset_info']['char_to_idx']),\n",
    "        max_sequence_length=checkpoint['metadata']['dataset_info']['max_sequence_length'] + 1\n",
    "    )\n",
    "\n",
    "    # Load weights\n",
    "    best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_model = best_model.to(tuner.device)\n",
    "    best_model.eval()\n",
    "\n",
    "    print(f\"✅ Best model loaded: {tuner.best_result['experiment_name']}\")\n",
    "    print(f\"📊 Character accuracy: {tuner.best_result['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"📊 Sequence accuracy: {tuner.best_result['best_val_seq_accuracy']:.4f}\")\n",
    "\n",
    "    # Test on a few validation samples\n",
    "    with torch.no_grad():\n",
    "        val_loader = tuner.create_data_loaders(32)[1]\n",
    "        images, targets, lengths = next(iter(val_loader))\n",
    "        images = images[:5].to(tuner.device)  # Test on 5 samples\n",
    "        targets = targets[:5]\n",
    "        lengths = lengths[:5]\n",
    "\n",
    "        outputs = best_model(images)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        idx_to_char = checkpoint['metadata']['dataset_info']['idx_to_char']\n",
    "\n",
    "        print(\"\\n🔍 Sample predictions:\")\n",
    "        for i in range(len(images)):\n",
    "            # Get actual text\n",
    "            actual_chars = [idx_to_char[str(idx.item())] for idx in targets[i][:lengths[i]-1]]  # -1 for EOS\n",
    "            actual_text = ''.join([char for char in actual_chars if char not in ['<PAD>', '<EOS>', '<BLANK>']])\n",
    "\n",
    "            # Get predicted text\n",
    "            pred_chars = [idx_to_char[str(idx.item())] for idx in predictions[i][:lengths[i]-1]]\n",
    "            pred_text = ''.join([char for char in pred_chars if char not in ['<PAD>', '<EOS>', '<BLANK>']])\n",
    "\n",
    "            print(f\"  Sample {i+1}: Actual='{actual_text}', Predicted='{pred_text}'\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No best model available to load\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "3K5QLxMOHkNF",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🎉 Hyperparameter Tuning Complete!\n",
    "\n",
    "### What was accomplished:\n",
    "\n",
    "1. **Environment Setup**: Configured Google Colab with GPU support\n",
    "2. **Data Generation**: Created 2000 synthetic Khmer digit samples\n",
    "3. **Model Architecture**: Implemented CNN-RNN-Attention OCR model\n",
    "4. **Hyperparameter Tuning**: Tested multiple configurations:\n",
    "   - Baseline GPU optimized\n",
    "   - Aggressive learning with large batches\n",
    "   - Large model with regularization\n",
    "5. **Results Analysis**: Generated comprehensive performance comparisons\n",
    "6. **Model Storage**: Saved best models to Google Drive\n",
    "\n",
    "### Files saved to Google Drive:\n",
    "- **Models**: `/content/drive/MyDrive/khmer_ocr_training/models/`\n",
    "- **Results**: `/content/drive/MyDrive/khmer_ocr_training/results/`\n",
    "- **Logs**: `/content/drive/MyDrive/khmer_ocr_training/logs/`\n",
    "\n",
    "### Next Steps:\n",
    "1. Download the best model from Google Drive\n",
    "2. Use the model for inference on real Khmer digit images\n",
    "3. Fine-tune further with real-world data\n",
    "4. Implement additional augmentations for better generalization\n",
    "\n",
    "### Performance Targets:\n",
    "- **Character Accuracy**: Target 85%+ (compare with results)\n",
    "- **Sequence Accuracy**: Target 70%+ (compare with results)\n",
    "\n",
    "The hyperparameter tuning system is now complete and ready for production use!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and generate summary\n",
    "print(\"💾 Saving results to Google Drive...\")\n",
    "results_file = tuner.save_results()\n",
    "\n",
    "# Generate summary report\n",
    "summary = tuner.generate_summary()\n",
    "print(\"📋 Generating experiment summary...\")\n",
    "\n",
    "# Print summary results\n",
    "completed_experiments = [r for r in tuner.results if r.get('status') == 'completed']\n",
    "failed_experiments = [r for r in tuner.results if r.get('status') == 'failed']\n",
    "\n",
    "print(f\"\\n📊 HYPERPARAMETER TUNING SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"✅ Completed experiments: {len(completed_experiments)}\")\n",
    "print(f\"❌ Failed experiments: {len(failed_experiments)}\")\n",
    "\n",
    "if tuner.best_result:\n",
    "    best = tuner.best_result\n",
    "    print(f\"\\n🏆 BEST EXPERIMENT: {best['experiment_name']}\")\n",
    "    print(f\"  📊 Character accuracy: {best['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"  📊 Sequence accuracy: {best['best_val_seq_accuracy']:.4f}\")\n",
    "    print(f\"  ⏱️ Training time: {best['training_time']/60:.1f} minutes\")\n",
    "    print(f\"  📈 Epochs trained: {best['epochs_trained']}\")\n",
    "    print(f\"  🧠 Model size: {best['hyperparameters']['model_size']}\")\n",
    "    print(f\"  📚 Batch size: {best['hyperparameters']['batch_size']}\")\n",
    "    print(f\"  🎯 Learning rate: {best['hyperparameters']['learning_rate']}\")\n",
    "    \n",
    "    if 'model_path' in best:\n",
    "        print(f\"  💾 Model saved to: {best['model_path']}\")\n",
    "\n",
    "print(f\"\\n💾 Full results saved to: {results_file}\")\n",
    "print(f\"📁 Check Google Drive: /content/drive/MyDrive/khmer_ocr_training/\")\n",
    "\n",
    "# Show detailed results for each experiment\n",
    "print(f\"\\n📋 DETAILED RESULTS:\")\n",
    "print(f\"{'='*80}\")\n",
    "for i, result in enumerate(completed_experiments, 1):\n",
    "    print(f\"\\n{i}. {result['experiment_name']}\")\n",
    "    print(f\"   Character Acc: {result['best_val_char_accuracy']:.4f}\")\n",
    "    print(f\"   Sequence Acc:  {result['best_val_seq_accuracy']:.4f}\")\n",
    "    print(f\"   Training Time: {result['training_time']/60:.1f} min\")\n",
    "    print(f\"   Model: {result['hyperparameters']['model_size']}\")\n",
    "    print(f\"   Batch: {result['hyperparameters']['batch_size']}\")\n",
    "    print(f\"   LR: {result['hyperparameters']['learning_rate']}\")\n",
    "\n",
    "# Generate comprehensive final report\n",
    "final_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'environment': {\n",
    "        'device': str(tuner.device),\n",
    "        'cuda_available': torch.cuda.is_available(),\n",
    "        'python_version': sys.version,\n",
    "        'pytorch_version': torch.__version__\n",
    "    },\n",
    "    'dataset_info': tuner.metadata['dataset_info'],\n",
    "    'experiment_summary': {\n",
    "        'total_experiments': len(tuner.results),\n",
    "        'completed': len(completed_experiments),\n",
    "        'failed': len(failed_experiments),\n",
    "        'success_rate': len(completed_experiments) / len(tuner.results) if tuner.results else 0\n",
    "    },\n",
    "    'best_result': tuner.best_result,\n",
    "    'all_results': tuner.results,\n",
    "    'summary': tuner.generate_summary()\n",
    "}\n",
    "\n",
    "# Save comprehensive report\n",
    "comprehensive_file = f\"{project_drive_path}/results/comprehensive_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(comprehensive_file, 'w') as f:\n",
    "    json.dump(tuner.convert_tensors_to_python(final_report), f, indent=2)\n",
    "\n",
    "print(f\"\\n📋 Comprehensive report saved to: {comprehensive_file}\")\n",
    "print(f\"🎉 Hyperparameter tuning completed successfully!\")\n",
    "\n",
    "# Plot results\n",
    "tuner.plot_results()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
