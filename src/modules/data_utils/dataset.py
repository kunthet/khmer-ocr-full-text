"""
PyTorch Dataset and DataLoader utilities for Khmer digits OCR.
"""

import os
import yaml
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union, Callable
import torch
from torch.utils.data import Dataset, DataLoader, random_split
from PIL import Image
import numpy as np


class KhmerDigitsDataset(Dataset):
    """
    PyTorch Dataset for loading Khmer digits synthetic data.
    
    This dataset loads images and their corresponding labels from the
    metadata file generated by the SyntheticDataGenerator.
    """
    
    def __init__(self, 
                 metadata_path: str,
                 split: str = 'train',
                 transform: Optional[Callable] = None,
                 target_transform: Optional[Callable] = None,
                 max_sequence_length: int = 8):
        """
        Initialize the Khmer digits dataset.
        
        Args:
            metadata_path: Path to the metadata.yaml file
            split: 'train' or 'val' or 'all'
            transform: Optional transform to apply to images
            target_transform: Optional transform to apply to labels
            max_sequence_length: Maximum sequence length for padding
        """
        self.metadata_path = metadata_path
        self.split = split
        self.transform = transform
        self.target_transform = target_transform
        self.max_sequence_length = max_sequence_length
        
        # Load metadata
        self.metadata = self._load_metadata()
        
        # Get samples for the specified split
        self.samples = self._get_samples_for_split()
        
        # Create character mappings
        self.char_to_idx, self.idx_to_char = self._create_character_mappings()
        
        print(f"Loaded {len(self.samples)} samples for split '{split}'")
    
    def _load_metadata(self) -> Dict:
        """Load metadata from YAML file."""
        if not os.path.exists(self.metadata_path):
            raise FileNotFoundError(f"Metadata file not found: {self.metadata_path}")
        
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _get_samples_for_split(self) -> List[Dict]:
        """Get samples for the specified split."""
        if self.split == 'all':
            # Combine train and val samples
            samples = []
            if 'train' in self.metadata and 'samples' in self.metadata['train']:
                samples.extend(self.metadata['train']['samples'])
            if 'val' in self.metadata and 'samples' in self.metadata['val']:
                samples.extend(self.metadata['val']['samples'])
            return samples
        
        elif self.split in ['train', 'val']:
            if self.split in self.metadata and 'samples' in self.metadata[self.split]:
                return self.metadata[self.split]['samples']
            else:
                raise ValueError(f"Split '{self.split}' not found in metadata")
        
        else:
            raise ValueError(f"Invalid split: {self.split}. Must be 'train', 'val', or 'all'")
    
    def _create_character_mappings(self) -> Tuple[Dict[str, int], Dict[int, str]]:
        """Create character to index and index to character mappings."""
        # Get character set from metadata if available
        if 'dataset_info' in self.metadata and 'character_set' in self.metadata['dataset_info']:
            chars = self.metadata['dataset_info']['character_set']
        else:
            # Fallback to default character set
            khmer_digits = ["០", "១", "២", "៣", "៤", "៥", "៦", "៧", "៨", "៩"]
            special_tokens = ["<EOS>", "<PAD>", "<BLANK>"]
            chars = khmer_digits + special_tokens
        
        char_to_idx = {char: idx for idx, char in enumerate(chars)}
        idx_to_char = {idx: char for idx, char in enumerate(chars)}
        
        return char_to_idx, idx_to_char
    
    def _encode_label(self, label: str) -> torch.Tensor:
        """
        Encode a text label to a tensor of character indices.
        
        Args:
            label: Text label (e.g., "០១២៣")
            
        Returns:
            Tensor of character indices with padding
        """
        # Convert characters to indices
        indices = [self.char_to_idx[char] for char in label if char in self.char_to_idx]
        
        # Add EOS token
        if '<EOS>' in self.char_to_idx:
            indices.append(self.char_to_idx['<EOS>'])
        
        # Pad sequence to max length
        pad_idx = self.char_to_idx.get('<PAD>', 0)
        while len(indices) < self.max_sequence_length + 1:  # +1 for EOS
            indices.append(pad_idx)
        
        return torch.tensor(indices[:self.max_sequence_length + 1], dtype=torch.long)
    
    def _decode_label(self, indices: torch.Tensor) -> str:
        """
        Decode a tensor of character indices back to text.
        
        Args:
            indices: Tensor of character indices
            
        Returns:
            Decoded text string
        """
        chars = []
        for idx in indices:
            idx_val = idx.item() if torch.is_tensor(idx) else idx
            if idx_val in self.idx_to_char:
                char = self.idx_to_char[idx_val]
                if char in ['<EOS>', '<PAD>']:
                    break
                chars.append(char)
        
        return ''.join(chars)
    
    def __len__(self) -> int:
        """Return the number of samples in the dataset."""
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, Dict]:
        """
        Get a sample from the dataset.
        
        Args:
            idx: Sample index
            
        Returns:
            Tuple of (image_tensor, label_tensor, metadata)
        """
        sample = self.samples[idx]
        
        # Load image
        image_path = sample['image_path']
        if not os.path.isabs(image_path):
            # The paths in metadata are already relative to project root
            # Just ensure we use forward slashes for cross-platform compatibility
            image_path = image_path.replace('\\', '/')
        
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            raise RuntimeError(f"Failed to load image {image_path}: {e}")
        
        # Apply image transform
        if self.transform:
            image = self.transform(image)
        
        # Encode label
        label = sample['label']
        label_tensor = self._encode_label(label)
        
        # Apply target transform
        if self.target_transform:
            label_tensor = self.target_transform(label_tensor)
        
        # Create metadata dict
        metadata = {
            'original_label': label,
            'font': sample.get('font', ''),
            'font_size': sample.get('font_size', 0),
            'sequence_length': sample.get('sequence_length', len(label)),
            'augmented': sample.get('augmented', False),
            'image_path': image_path
        }
        
        return image, label_tensor, metadata
    
    def get_sample_info(self, idx: int) -> Dict:
        """Get detailed information about a specific sample."""
        sample = self.samples[idx]
        image, label_tensor, metadata = self[idx]
        
        return {
            'index': idx,
            'label': sample['label'],
            'encoded_label': label_tensor.tolist(),
            'decoded_label': self._decode_label(label_tensor),
            'image_shape': tuple(image.shape) if torch.is_tensor(image) else image.size,
            'metadata': metadata
        }
    
    def get_character_mappings(self) -> Tuple[Dict[str, int], Dict[int, str]]:
        """Get character to index and index to character mappings."""
        return self.char_to_idx, self.idx_to_char
    
    def get_dataset_stats(self) -> Dict:
        """Get statistics about the dataset."""
        sequence_lengths = [sample['sequence_length'] for sample in self.samples]
        fonts = [sample.get('font', 'unknown') for sample in self.samples]
        augmented_count = sum(1 for sample in self.samples if sample.get('augmented', False))
        
        return {
            'total_samples': len(self.samples),
            'sequence_length_stats': {
                'min': min(sequence_lengths),
                'max': max(sequence_lengths),
                'mean': np.mean(sequence_lengths),
                'std': np.std(sequence_lengths)
            },
            'font_distribution': {font: fonts.count(font) for font in set(fonts)},
            'augmented_samples': augmented_count,
            'augmentation_rate': augmented_count / len(self.samples),
            'character_set_size': len(self.char_to_idx),
            'max_sequence_length': self.max_sequence_length
        }


def create_data_loaders(metadata_path: str,
                       train_transform: Optional[Callable] = None,
                       val_transform: Optional[Callable] = None,
                       batch_size: int = 32,
                       num_workers: int = 4,
                       pin_memory: bool = True,
                       shuffle_train: bool = True) -> Tuple[DataLoader, DataLoader]:
    """
    Create train and validation DataLoaders.
    
    Args:
        metadata_path: Path to the metadata.yaml file
        train_transform: Transform to apply to training images
        val_transform: Transform to apply to validation images
        batch_size: Batch size for both loaders
        num_workers: Number of worker processes for data loading
        pin_memory: Whether to pin memory for faster GPU transfer
        shuffle_train: Whether to shuffle the training data
        
    Returns:
        Tuple of (train_loader, val_loader)
    """
    # Create datasets
    train_dataset = KhmerDigitsDataset(
        metadata_path=metadata_path,
        split='train',
        transform=train_transform
    )
    
    val_dataset = KhmerDigitsDataset(
        metadata_path=metadata_path,
        split='val',
        transform=val_transform
    )
    
    # Create data loaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=shuffle_train,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=True,  # Drop last incomplete batch for training
        collate_fn=collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=False,
        collate_fn=collate_fn
    )
    
    return train_loader, val_loader


def create_combined_data_loader(metadata_path: str,
                               transform: Optional[Callable] = None,
                               batch_size: int = 32,
                               train_ratio: float = 0.8,
                               num_workers: int = 4,
                               pin_memory: bool = True) -> Tuple[DataLoader, DataLoader]:
    """
    Create train and validation DataLoaders by splitting a combined dataset.
    
    This is useful when you want to create a different train/val split
    than what's in the metadata file.
    
    Args:
        metadata_path: Path to the metadata.yaml file
        transform: Transform to apply to all images
        batch_size: Batch size for both loaders
        train_ratio: Ratio of data to use for training
        num_workers: Number of worker processes for data loading
        pin_memory: Whether to pin memory for faster GPU transfer
        
    Returns:
        Tuple of (train_loader, val_loader)
    """
    # Create combined dataset
    full_dataset = KhmerDigitsDataset(
        metadata_path=metadata_path,
        split='all',
        transform=transform
    )
    
    # Calculate split sizes
    total_size = len(full_dataset)
    train_size = int(total_size * train_ratio)
    val_size = total_size - train_size
    
    # Split dataset
    train_dataset, val_dataset = random_split(
        full_dataset, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(42)  # For reproducibility
    )
    
    # Create data loaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=True,
        collate_fn=collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=False,
        collate_fn=collate_fn
    )
    
    return train_loader, val_loader


def collate_fn(batch: List[Tuple[torch.Tensor, torch.Tensor, Dict]]) -> Tuple[torch.Tensor, torch.Tensor, List[Dict]]:
    """
    Custom collate function for batching variable-length sequences.
    
    Args:
        batch: List of (image, label, metadata) tuples
        
    Returns:
        Tuple of (batched_images, batched_labels, metadata_list)
    """
    images, labels, metadata_list = zip(*batch)
    
    # Stack images
    images = torch.stack(images, dim=0)
    
    # Stack labels (they should already be padded to the same length)
    labels = torch.stack(labels, dim=0)
    
    return images, labels, list(metadata_list) 